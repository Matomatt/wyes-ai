{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40MbOJ1JSc79"
   },
   "source": [
    "# [Sequence to Sequence (seq2seq) Recurrent Neural Network (RNN) for Time Series Forecasting](https://github.com/guillaume-chevalier/seq2seq-signal-prediction)\n",
    "\n",
    "***Note: You can find here the accompanying [seq2seq RNN forecasting presentation's slides](https://drive.google.com/drive/folders/1U0xQMxVespjQilMhYW4mDxN02IwEW67I), as well as the Google Colab file for running the present notebook (if you're not already in Colab).***\n",
    "\n",
    "This is a series of exercises that you can try to solve to learn how to code Encoder-Decoder Sequence to Sequence Recurrent Neural Networks (seq2seq RNNs). You can solve different simple toy signal prediction problems. Seq2seq architectures may also be used for other sophisticated purposes, such as for Natural Language Processing (NLP). \n",
    "\n",
    "In this project are given 4 exercises of gradually increasing difficulty. I take for granted that you have at least some knowledge of how RNN works and how can they be shaped into an encoder and a decoder seq2seq setup of the most simple form (without attention). To learn more about RNNs in TensorFlow, you may want to visit [this other RNN project](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition) which I have built for that.\n",
    "\n",
    "The current project is a series of example I have first built in French, but I haven't got the time to generate all the charts anew with proper English text. I have built this project at first for the practical part of the third hour of a [master class](https://webaquebec.org/classes-de-maitre/deep-learning-avec-tensorflow) conference I presented at the Web At Quebec (WAQ), originally in March 2017.\n",
    "\n",
    "## How to use this \".ipynb\" Python notebook ?\n",
    "\n",
    "I made available an \".py\" Python version of this tutorial within the [repository](https://github.com/guillaume-chevalier/seq2seq-signal-prediction), but it's more convenient to run the code inside the notebook or within Google Colab.\n",
    "\n",
    "For running the notebook, you can run `jupyter-notebook` in the command-line to launch the web notebook IDE, and choose the `.ipynb` file. For Google Colab, if you want to run the code using GPU, make sure to do `Runtime > Change Runtime Type` and to select `GPU` for `Python 3`.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Note that the dataset changes in function of the exercice. Most of the time, you will have to edit the neural networks' training parameter to succeed in doing the exercise, but at a certain point, changes in the architecture itself will be asked and required. The datasets used for this exercises are found in [`datasets.py`](https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/datasets.py).\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "In theory, it is possible to create a perfect prediction of the signal for this exercise as it is deterministic. The neural network's parameters has been set to \"somehow\" acceptable values for a first training. You'll want to play with the hyperparameters until you reach predictions like those:\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E1.png?raw=true\" />\n",
    "\n",
    "Note: the neural network sees only what is to the left of the chart and is trained to predict what is at the right (predictions in yellow). \n",
    "\n",
    "We have 2 time series at once to predict, which are tied together. That means our neural network processes multidimensional data. A simple example would be to receive as an argument the past values of multiple stock market symbols in order to predict the future values of all those symbols with the neural network, which values are evolving together in time. That is what we will do in the exercise 4 with USD and EUR values of the BTC that we'll see both at once. \n",
    "\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Here, rather than 2 signals in parallel to predict, we have only one, for simplicity. HOWEVER, this signal is a superposition of two sine waves of varying wavelenght and offset (and restricted to a particular min and max limit of wavelengts). \n",
    "\n",
    "In order to finish this exercise properly, you will need to edit the neural network's hyperparameters. We would recommend first trying with hyperparameters like those:\n",
    "\n",
    "- `n_samples = 125000`\n",
    "- `epochs = 1`\n",
    "- `batch_size = 50`\n",
    "- `hidden_dim = 35`\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E2.png?raw=true\" />\n",
    "\n",
    "Here are predictions achieved with a bigger neural networks with 3 stacked recurrent cells and a width of 500 hidden units for each of those cells: \n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E2_2.png?raw=true\" />\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E2_3.png?raw=true\" />\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E2_3.png?raw=true\" />\n",
    "\n",
    "Note that it would be possible to obtain better results with a smaller neural network, provided better training hyperparameters and a longer training, adding dropout and a few things, and on. \n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "This exercise is similar to the previous one, except that the input data given to the encoder is noisy. The expected output is NOT noisy. This makes the task a bit harder. In this specific data context, we can call our neuralnetwork a denoising autoregressive autoencoder. Here is a good example of what a training example (and a prediction) could now looks like :\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E3.png?raw=true\" />\n",
    "\n",
    "Therefore the neural network is brought to denoise the signal to interpret its future smooth values. Here are some example of better predictions on this version of the dataset :\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E3_1.png?raw=true\" />\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E3_2.png?raw=true\" />\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E3_3.png?raw=true\" />\n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E3_4.png?raw=true\" />\n",
    "\n",
    "Similarly as I said for the exercise 2, it would be possible here too to obtain better results. Note that it would also have been possible to ask you to predict to reconstruct the denoised signal from the noisy input (rather than trying to predict the future values of it) as a denoising autoencoder. This type of architecture is also useful for data compression, such as manipulating images, for instance.\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "This exercise is much harder than the previous ones and is built more as an open-ended suggestion. It is to predict the future value of the Bitcoin's price. We have here some daily market data of the bitcoin's value, that is, BTC/USD and BTC/EUR. This is not enough to build a good predictor - at least having data precise at the minute level, or second level, would be more interesting. Here is a prediction that was made on the actual future values, the neural network has not been trained on the future values shown here so this is a legitimate prediction, given a well-enough model trained on the task: \n",
    "\n",
    "<img src=\"https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/images/E5.png?raw=true\" />\n",
    "\n",
    "Disclaimer: this prediction of the future values was really good and you should not expect predictions to be always that good using as few data as actually (side note: the other prediction charts in this project are all \"average\" except this one). I mostly didn't really took the time to compare this model to other financial models. For this exercise, you can try to plug more valuable financial data into the model in order to make more accurate predictions. Let me remind you that I provided the code for the datasets in [`datasets.py`](https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/datasets.py), but that could be replaced with more comprehensive data for predicting more accurately the Bitcoin. \n",
    "\n",
    "The input and output dimensions of the model is 2D accepts (BTC/USD and BTC/EUR). As an example, you could create additionnal input dimensions/streams which could contain meteo data and more financial data, such as the S&P 500, the Dow Jones, and so on. Other more creative input data could be sine waves (or other-type-shaped waves such as saw waves or triangles or two signals for `cos` and `sin`) representing the fluctuation of minutes, hours, days, weeks, months, years, moon cycles, and on (as we did in [Neuraxio's Time Series Solution](https://www.neuraxio.com/en/time-series-solution)). This could be combined with a stream of social media [sentiment analysis](https://github.com/Neuraxio/Sentiment-Analysis-AutoML) about the word \"Bitcoin\" to have another input signal which is more human-based and abstract. It is also interesting to know [where is the bitcoin most used](http://images.google.com/search?tbm=isch&q=bitcoin+heatmap+world).\n",
    "\n",
    "With all the above-mentionned examples, it would be possible to have all of this as input features, at every time steps: (BTC/USD, BTC/EUR, Dow_Jones, SP_500, hour_of_day, day_of_week, day_of_month, week_of_year, year, moon_cycle, meteo_USA, meteo_EUROPE, social_sentiment). Finally, there could be those two output features, or more: (BTC/USD, BTC/EUR).\n",
    "\n",
    "This prediction concept and similar time series forecasting algorithms can apply to many many things, such as auto-correcting machines for Industry 4.0, quality assurance in production chains, traffic forecast, meteo prediction, movements and action prediction, and lots of other types of shot-term and mid-term statistical predictions or forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvzSMI0zSc8A"
   },
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "colab_type": "code",
    "id": "_MtEmQ6pS3Ft",
    "outputId": "53616a33-82b5-45f0-c25e-cfbb76a70c70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\users\\maxime\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"d:\\users\\maxime\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\Users\\maxime\\Anaconda3\\Scripts\\pip.exe\\__main__.py\", line 5, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.1 neuraxle==0.3.1 neuraxle_tensorflow==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDZY7mPVUvRv"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download_import(filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        # Downloading like that is needed because of Colab operating from a Google Drive folder that is just \"shared with you\".\n",
    "        # https://drive.google.com/drive/folders/1U0xQMxVespjQilMhYW4mDxN02IwEW67I\n",
    "        url = 'https://raw.githubusercontent.com/guillaume-chevalier/seq2seq-signal-prediction/master/{}'.format(filename)\n",
    "        f.write(urllib.request.urlopen(url).read())\n",
    "\n",
    "download_import(\"datasets.py\")\n",
    "download_import(\"plotting.py\")\n",
    "download_import(\"steps.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "400uSZsmSc8B"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuraxle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-635ff535bba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_container\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataContainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperparameterSamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mneuraxle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetaopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mValidationSplitWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neuraxle'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from logging import warning\n",
    "\n",
    "import tensorflow as tf\n",
    "from neuraxle.data_container import DataContainer\n",
    "from neuraxle.hyperparams.space import HyperparameterSamples\n",
    "from neuraxle.metaopt.random import ValidationSplitWrapper\n",
    "from neuraxle.metrics import MetricsWrapper\n",
    "from neuraxle.pipeline import Pipeline, MiniBatchSequentialPipeline\n",
    "from neuraxle.steps.data import EpochRepeater, DataShuffler\n",
    "from neuraxle.steps.flow import TrainOnlyWrapper\n",
    "from neuraxle.steps.loop import ForEachDataInput\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow_core.python.client import device_lib\n",
    "from tensorflow_core.python.keras import Input, Model\n",
    "from tensorflow_core.python.keras.layers import GRUCell, RNN, Dense\n",
    "from tensorflow_core.python.training.adam import AdamOptimizer\n",
    "\n",
    "from datasets import generate_data\n",
    "from datasets import metric_3d_to_2d_wrapper\n",
    "from neuraxle_tensorflow.tensorflow_v1 import TensorflowV1ModelStep\n",
    "from neuraxle_tensorflow.tensorflow_v2 import Tensorflow2ModelStep\n",
    "from plotting import plot_metrics\n",
    "from steps import MeanStdNormalizer, ToNumpy, PlotPredictionsWrapper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wbwtXM6BeSbX",
    "outputId": "a2d192dc-d6a9-4712-d427-b6f3c3a82bd8"
   },
   "outputs": [],
   "source": [
    "def choose_tf_device():\n",
    "    \"\"\"\n",
    "    Choose a TensorFlow device (e.g.: GPU if available) to compute on.\n",
    "    \"\"\"\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    devices = [x.name for x in device_lib.list_local_devices()]\n",
    "    print('You can use the following tf devices: {}'.format(devices))\n",
    "    try:\n",
    "        chosen_device = [d for d in devices if 'gpu' in d.lower()][0]\n",
    "    except:\n",
    "        warning(\n",
    "            \"No GPU device found. Please make sure to do `Runtime > Change Runtime Type` and select GPU for Python 3.\")\n",
    "        chosen_device = devices[0]\n",
    "    print('Chosen Device: {}'.format(chosen_device))\n",
    "    return chosen_device\n",
    "\n",
    "chosen_device = choose_tf_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NBda5ODSc8A"
   },
   "source": [
    "\n",
    "## Definition of the Neural Architecture\n",
    "\n",
    "### Basic Sequence To Sequence (seq2seq) RNN\n",
    "\n",
    "Here is a basic sequence to sequence neural architecture. \"ABC\" is a past input. \"WXYZ\" is here both a future output and a future input as a feedback loop. This feedback loop has been proven to improve the results of RNNs in some cases ([read more](https://github.com/guillaume-chevalier/Awesome-Deep-Learning-Resources#recurrent-neural-networks)). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/basic_seq2seq.png\" />\n",
    "\n",
    "In our case, we won't do such a feedback loop, as it requires more complex sampling during training and testing and would be too complicated for today's practical example.\n",
    "\n",
    "### Our Stacked GRU seq2seq RNN\n",
    "\n",
    "Here is what we do. The \"H\" is the hidden output of the encoder RNN's last time step. We replicate this value across time in the future as a future data input to the RNN to make it remember the context of the present at all times when predicting the future.\n",
    "\n",
    "<img src=\"https://github.com/Neuraxio/Machine-Learning-Figures/blob/master/encoder-decoder-seq-to-seq.png?raw=true\" />\n",
    "\n",
    " Notice that we could have instead plugged an attention mechanism here. Doing so would allow the neural net to re-analyze the past at every step in the future if it needed. Attention mechanisms would be more useful in contexts of Machine Translation (MT), where it's sometimes important to go see back \"word per word\" what was written, rather than being limited by our short term memory that was accumulated once after reading everything, for instance. More recent Machine Translation approaches like BERT ([read on BERT](https://www.umaneo.com/post/a-review-of-recent-natural-language-processing-approaches) / [see example of using BERT](https://github.com/guillaume-chevalier/ReuBERT)) only uses attention mechanisms without RNNs (with some tradeoffs, however).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-bM8PQ6ASc8E"
   },
   "source": [
    "## Creating Tensorflow 2 Model\n",
    "\n",
    "Let's proceed and code what we see in the image just above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UtzC2A0Sc8F"
   },
   "outputs": [],
   "source": [
    "def create_model(step: Tensorflow2ModelStep) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "   Create a TensorFlow v2 sequence to sequence (seq2seq) encoder-decoder model.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n",
    "   :return: TensorFlow v2 Keras model\n",
    "    \"\"\"\n",
    "    # shape: (batch_size, seq_length, input_dim)\n",
    "    encoder_inputs = Input(\n",
    "        shape=(None, step.hyperparams['input_dim']),\n",
    "        batch_size=None,\n",
    "        dtype=tf.dtypes.float32,\n",
    "        name='encoder_inputs'\n",
    "    )\n",
    "\n",
    "    last_encoder_outputs, last_encoders_states = _create_encoder(step, encoder_inputs)\n",
    "    decoder_outputs = _create_decoder(step, last_encoder_outputs, last_encoders_states)\n",
    "\n",
    "    return Model(encoder_inputs, decoder_outputs)\n",
    "\n",
    "def _create_encoder(step: Tensorflow2ModelStep, encoder_inputs: Input) -> (tf.Tensor, List[tf.Tensor]):\n",
    "    \"\"\"\n",
    "   Create an encoder RNN using GRU Cells. GRU cells are similar to LSTM cells.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (class Tensorflow2ModelStep)\n",
    "    :param encoder_inputs: encoder inputs layer of shape (batch_size, seq_length, input_dim)\n",
    "    :return: (last encoder outputs, last stacked encoders states)\n",
    "                last_encoder_outputs shape: (batch_size, hidden_dim)\n",
    "                last_encoder_states shape: (layers_stacked_count, batch_size, hidden_dim)\n",
    "    \"\"\"\n",
    "    encoder = RNN(cell=_create_stacked_rnn_cells(step), return_sequences=False, return_state=True)\n",
    "\n",
    "    last_encoder_outputs_and_states = encoder(encoder_inputs)\n",
    "    # last_encoder_outputs shape: (batch_size, hidden_dim)\n",
    "    # last_encoder_states shape: (layers_stacked_count, batch_size, hidden_dim)\n",
    "\n",
    "    # refer to: https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN?version=stable#output_shape_2\n",
    "    last_encoder_outputs, *last_encoders_states = last_encoder_outputs_and_states\n",
    "    return last_encoder_outputs, last_encoders_states\n",
    "\n",
    "def _create_decoder(step: Tensorflow2ModelStep, last_encoder_outputs: tf.Tensor, last_encoders_states: List[tf.Tensor]) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "   Create a decoder RNN using GRU cells.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n",
    "    :param last_encoders_states: last encoder states tensor\n",
    "    :param last_encoder_outputs: last encoder output tensor\n",
    "    :return: decoder output\n",
    "    \"\"\"\n",
    "    decoder_lstm = RNN(cell=_create_stacked_rnn_cells(step), return_sequences=True, return_state=False)\n",
    "\n",
    "    last_encoder_output = tf.expand_dims(last_encoder_outputs, axis=1)\n",
    "    # last encoder output shape: (batch_size, 1, hidden_dim)\n",
    "\n",
    "    replicated_last_encoder_output = tf.repeat(\n",
    "        input=last_encoder_output,\n",
    "        repeats=step.hyperparams['window_size_future'],\n",
    "        axis=1\n",
    "    )\n",
    "    # replicated last encoder output shape: (batch_size, window_size_future, hidden_dim)\n",
    "\n",
    "    decoder_outputs = decoder_lstm(replicated_last_encoder_output, initial_state=last_encoders_states)\n",
    "    # decoder outputs shape: (batch_size, window_size_future, hidden_dim)\n",
    "\n",
    "    decoder_dense = Dense(step.hyperparams['output_dim'])\n",
    "    # decoder outputs shape: (batch_size, window_size_future, output_dim)\n",
    "\n",
    "    return decoder_dense(decoder_outputs)\n",
    "\n",
    "def _create_stacked_rnn_cells(step: Tensorflow2ModelStep) -> List[GRUCell]:\n",
    "    \"\"\"\n",
    "   Create a `layers_stacked_count` amount of GRU cells and stack them on top of each other.\n",
    "   They have a `hidden_dim` number of neuron layer size.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n",
    "    :return: list of gru cells\n",
    "    \"\"\"\n",
    "    cells = []\n",
    "    for _ in range(step.hyperparams['layers_stacked_count']):\n",
    "        cells.append(GRUCell(step.hyperparams['hidden_dim']))\n",
    "\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FL3FugpjSc8H"
   },
   "source": [
    "## Create Loss\n",
    "\n",
    "Using the Mean Squared Error (MSE) and weight decay (L2 penality) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OikSbwugSc8I"
   },
   "outputs": [],
   "source": [
    "def create_loss(step: Tensorflow2ModelStep, expected_outputs: tf.Tensor, predicted_outputs: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Create model loss.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n",
    "   :param expected_outputs: expected outputs of shape (batch_size, window_size_future, output_dim)\n",
    "   :param predicted_outputs: expected outputs of shape (batch_size, window_size_future, output_dim)\n",
    "   :return: loss (a tf Tensor that is a float)\n",
    "    \"\"\"\n",
    "    l2 = step.hyperparams['lambda_loss_amount'] * sum(\n",
    "        tf.reduce_mean(tf.nn.l2_loss(tf_var))\n",
    "        for tf_var in step.model.trainable_variables\n",
    "    )\n",
    "\n",
    "    output_loss = sum(\n",
    "        tf.reduce_mean(tf.nn.l2_loss(pred - expected))\n",
    "        for pred, expected in zip(predicted_outputs, expected_outputs)\n",
    "    ) / float(len(predicted_outputs))\n",
    "\n",
    "    return output_loss + l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsEd_ugfSc8J"
   },
   "source": [
    "## Create Optimizer\n",
    "\n",
    "Adam often wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2z9cWcNSc8K"
   },
   "outputs": [],
   "source": [
    "def create_optimizer(step: TensorflowV1ModelStep) -> AdamOptimizer:\n",
    "    \"\"\"\n",
    "   Create a TensorFlow 2 Optimizer: here the AdamOptimizer.\n",
    "\n",
    "   :param step: The base Neuraxle step for TensorFlow v2 (Tensorflow2ModelStep)\n",
    "    :return: optimizer\n",
    "    \"\"\"\n",
    "    return AdamOptimizer(learning_rate=step.hyperparams['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gMFysQWSc8M"
   },
   "source": [
    "## Generate or Load the Data\n",
    "\n",
    "To change which exercise you are doing, change the value of the `exercise_number` variable (that is, the first line in the code cell below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "B9S5QLCRSc8N",
    "outputId": "6fb42991-e405-4263-cca4-1e04483450bf"
   },
   "outputs": [],
   "source": [
    "exercice_number = 1\n",
    "print('exercice {}\\n=================='.format(exercice_number))\n",
    "\n",
    "data_inputs, expected_outputs = generate_data(\n",
    "    # See: https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/datasets.py\n",
    "    exercice_number=exercice_number,\n",
    "    n_samples=None,\n",
    "    window_size_past=None,\n",
    "    window_size_future=None\n",
    ")\n",
    "\n",
    "print('data_inputs shape: {} => (n_samples, window_size_past, input_dim)'.format(data_inputs.shape))\n",
    "print('expected_outputs shape: {} => (n_samples, window_size_future, output_dim)'.format(expected_outputs.shape))\n",
    "\n",
    "sequence_length = data_inputs.shape[1]\n",
    "input_dim = data_inputs.shape[2]\n",
    "output_dim = expected_outputs.shape[2]\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 15\n",
    "validation_size = 0.15\n",
    "max_plotted_validation_predictions = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDB-sXuMSc8P"
   },
   "source": [
    "## Neural Network's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "58aDFRrSSc8P",
    "outputId": "fd5c77f5-5331-4760-ae6d-16bea72ab302"
   },
   "outputs": [],
   "source": [
    "seq2seq_pipeline_hyperparams = HyperparameterSamples({\n",
    "    'hidden_dim': 12,\n",
    "    'layers_stacked_count': 2,\n",
    "    'lambda_loss_amount': 0.0003,\n",
    "    'learning_rate': 0.001,\n",
    "    'window_size_future': sequence_length,\n",
    "    'output_dim': output_dim,\n",
    "    'input_dim': input_dim\n",
    "})\n",
    "\n",
    "print('hyperparams: {}'.format(seq2seq_pipeline_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RQ21el8Sc8R"
   },
   "source": [
    "## The Pipeline\n",
    "\n",
    "Seeing [dirty Machine Learning code](https://www.neuraxio.com/en/blog/clean-code/2019/12/26/machine-learning-competition-code.html) has almost become the industry norm. And it is for sure contributing to the reasons [why 87% of data science projects never make it into production](https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/).\n",
    "\n",
    "Here, we use advanced design patterns (pipe and filter) to do what we call [clean machine learning](https://www.neuraxio.com/en/blog/neuraxle/2019/10/26/neat-machine-learning-pipelines.html). Those design patterns are inspired of [scikit-learn's pipeline class](https://www.neuraxio.com/en/blog/scikit-learn/2020/01/03/what-is-wrong-with-scikit-learn.html).\n",
    "\n",
    "### Defining the Deep Learning Pipeline\n",
    "\n",
    "Here, we first define the pipeline using a [Tensorflow2ModelStep](https://github.com/Neuraxio/Neuraxle-TensorFlow). The MeanStdNormalizer helps us normalize data, as a neural network needs to see normalized data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjeTOLg3Sc8S"
   },
   "outputs": [],
   "source": [
    "feature_0_metric = metric_3d_to_2d_wrapper(mean_squared_error)\n",
    "metrics = {'mse': feature_0_metric}\n",
    "\n",
    "signal_prediction_pipeline = Pipeline([\n",
    "    ForEachDataInput(MeanStdNormalizer()),\n",
    "    ToNumpy(),\n",
    "    PlotPredictionsWrapper(Tensorflow2ModelStep(\n",
    "        # See: https://github.com/Neuraxio/Neuraxle-TensorFlow\n",
    "        create_model=create_model,\n",
    "        create_loss=create_loss,\n",
    "        create_optimizer=create_optimizer,\n",
    "        expected_outputs_dtype=tf.dtypes.float32,\n",
    "        data_inputs_dtype=tf.dtypes.float32,\n",
    "        print_loss=False,\n",
    "        device_name=chosen_device\n",
    ").set_hyperparams(seq2seq_pipeline_hyperparams))]).set_name('SignalPrediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdKQiQ7CrSPM"
   },
   "source": [
    "### Defining how to Train our Deep Learning Pipeline\n",
    "\n",
    "Finally, let's wrap the pipeline with an EpochRepeater, ValidationSplitWrapper, DataShuffler, MiniBatchSequentialPipeline and MetricsWrapper to handle all it needs to be trained. You can refer to [Neuraxle's Documentation](https://www.neuraxle.org/stable/index.html) for more info on those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "BWYwE657rVGo",
    "outputId": "b3690b1f-779e-448c-87d7-c675eea6a86d"
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([EpochRepeater(\n",
    "    ValidationSplitWrapper(\n",
    "        MetricsWrapper(Pipeline([\n",
    "            TrainOnlyWrapper(DataShuffler()),\n",
    "            MiniBatchSequentialPipeline([\n",
    "                MetricsWrapper(\n",
    "                    signal_prediction_pipeline,\n",
    "                    metrics=metrics,\n",
    "                    name='batch_metrics'\n",
    "                )], batch_size=batch_size)\n",
    "            ]), \n",
    "            metrics=metrics,\n",
    "            name='epoch_metrics',\n",
    "            print_metrics=True\n",
    "        ),\n",
    "        test_size=validation_size,\n",
    "        scoring_function=feature_0_metric), \n",
    "    epochs=epochs)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFvoKkZmSc8U"
   },
   "source": [
    "## Training of the neural net\n",
    "\n",
    "Time to fit the model on the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q3R3K2soSc8U",
    "outputId": "b0a1b69c-9c2c-48b4-a11a-483a61450958"
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline, outputs = pipeline.fit_transform(data_inputs, expected_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydLUnLIGSc8W"
   },
   "source": [
    "## Visualizing Test Predictions\n",
    "\n",
    "See how your training performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "-sIIbGNJSc8X",
    "outputId": "4c72b344-8fb2-4bef-953e-2d5a9f228a1d"
   },
   "outputs": [],
   "source": [
    "plot_metrics(pipeline=pipeline, exercice_number=exercice_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GpBbXx11ZkPE",
    "outputId": "c311e20e-cc12-4832-9984-6304c7004b14"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(data_inputs, expected_outputs, pipeline, max_plotted_predictions):\n",
    "    _, _, data_inputs_validation, expected_outputs_validation = \\\n",
    "        pipeline.get_step_by_name('ValidationSplitWrapper').split(data_inputs, expected_outputs)\n",
    "\n",
    "    pipeline.apply('toggle_plotting')\n",
    "    pipeline.apply('set_max_plotted_predictions', max_plotted_predictions)\n",
    "\n",
    "    signal_prediction_pipeline = pipeline.get_step_by_name('SignalPrediction')\n",
    "    signal_prediction_pipeline.transform_data_container(DataContainer(\n",
    "        data_inputs=data_inputs_validation,\n",
    "        expected_outputs=expected_outputs_validation\n",
    "    ))\n",
    "\n",
    "plot_predictions(data_inputs, expected_outputs, pipeline, max_plotted_validation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1vnmpbzSc8Z"
   },
   "source": [
    "## Conclusion \n",
    "\n",
    "Recurrent Neural Networks are fabulous. They can learn to predict complex things. They can read multiple features from sequence data, and output variable length sequences of the same features, or of totally different features. Some people even use RNNs combined with other neural network architectures, such as CNNs, for automatic image captioning (CNN encoder for images, RNN decoder for the description). \n",
    "\n",
    "Here is what you learned:\n",
    "- Building a time series machine learning pipeline\n",
    "- Building a TensorFlow v2 encoder decoder sequence to sequence model\n",
    "- Building a clean machine learning pipeline using Neuraxle\n",
    "- Properly split the data for training and validation\n",
    "- Shuffling the data during training\n",
    "- Using minibatches to process the data using a MiniBatchSequentialPipeline\n",
    "\n",
    "\n",
    "## About Us\n",
    "\n",
    "The Author, [Guillaume Chevalier](https://guillaume-chevalier.com/):\n",
    "- https://ca.linkedin.com/in/chevalierg\n",
    "- https://twitter.com/guillaume_che\n",
    "- https://github.com/guillaume-chevalier/\n",
    "\n",
    "This original project was updated and maintained with the support of our team, contributors and business partners at [Neuraxio](https://www.neuraxio.com/en/):\n",
    "- https://ca.linkedin.com/company/neuraxio\n",
    "- https://twitter.com/neuraxio_inc\n",
    "- https://github.com/Neuraxio/\n",
    "\n",
    "## License & Citation\n",
    "\n",
    "This project is free to use according to the [Apache 2.0 License](https://github.com/guillaume-chevalier/seq2seq-signal-prediction/blob/master/LICENSE) as long as you link to the project (citation), and that you respect the License (read the License for more details). You can cite by pointing to the following link: \n",
    "- https://github.com/guillaume-chevalier/seq2seq-signal-prediction\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
