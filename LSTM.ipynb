{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = [[[(i+j)/100] for i in range(5)] for j in range(100)]\n",
    "Target = [(i+5)/100 for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On convertit notre suite de nombre dans une array\n",
    "data = np.array(Data, dtype=float);\n",
    "#On convertit notre cible dans une array\n",
    "target = np.array(Target, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition des variables\n",
    "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèle du RNN\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D'après le sequential Model \"model.add(layers.Dense(2, activation=\"relu\"))\"\n",
    "#Le batch_input shape est défini par (Nombre d'input/None si inconnu,longueur de la séquence,longueur du vecteur)\n",
    "#On utilise deux LST, l'une qui renvoie une séquence de nombre et une qui renvoit uniquement la dernière valeu\n",
    "model.add(LSTM((1),batch_input_shape=(None,None,1),return_sequences=True))\n",
    "model.add(LSTM((1),return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure notre modele pour le training\n",
    "#On définit la loss comme l erreur absolue moyenne\n",
    "#On utilise l'algorithme d'Adam qui est une extension à la descente des gradients pour ces raisons là : \n",
    "#1)Straightforward to implement.\n",
    "#2)Computationally efficient.\n",
    "#3)Little memory requirements.\n",
    "#4)Invariant to diagonal rescale of the gradients.\n",
    "#5)Well suited for problems that are large in terms of data and/or parameters.\n",
    "#6)Appropriate for non-stationary objectives.\n",
    "#7)Appropriate for problems with very noisy/or sparse gradients.\n",
    "#8)Hyper-parameters have intuitive interpretation and typically require little tuning.\n",
    "#lien de l'explication ici : https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "#On définit ensuite le champs d'analyse sur la précision\n",
    "model.compile(loss='mean_absolute_error',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 1)           12        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6457 - accuracy: 0.0000e+00 - val_loss: 0.5195 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.6419 - accuracy: 0.0000e+00 - val_loss: 0.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.6382 - accuracy: 0.0000e+00 - val_loss: 0.5126 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.6346 - accuracy: 0.0000e+00 - val_loss: 0.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.6310 - accuracy: 0.0000e+00 - val_loss: 0.5059 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.6275 - accuracy: 0.0000e+00 - val_loss: 0.5027 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "80/80 [==============================] - 0s 250us/step - loss: 0.6240 - accuracy: 0.0000e+00 - val_loss: 0.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.6206 - accuracy: 0.0000e+00 - val_loss: 0.4964 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.6173 - accuracy: 0.0000e+00 - val_loss: 0.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.6141 - accuracy: 0.0000e+00 - val_loss: 0.4903 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.6109 - accuracy: 0.0000e+00 - val_loss: 0.4874 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.6077 - accuracy: 0.0000e+00 - val_loss: 0.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.6046 - accuracy: 0.0000e+00 - val_loss: 0.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.6017 - accuracy: 0.0000e+00 - val_loss: 0.4789 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5987 - accuracy: 0.0000e+00 - val_loss: 0.4762 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5958 - accuracy: 0.0000e+00 - val_loss: 0.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5930 - accuracy: 0.0000e+00 - val_loss: 0.4709 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5901 - accuracy: 0.0000e+00 - val_loss: 0.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5874 - accuracy: 0.0000e+00 - val_loss: 0.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5847 - accuracy: 0.0000e+00 - val_loss: 0.4632 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5821 - accuracy: 0.0000e+00 - val_loss: 0.4608 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5794 - accuracy: 0.0000e+00 - val_loss: 0.4583 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5769 - accuracy: 0.0000e+00 - val_loss: 0.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5743 - accuracy: 0.0000e+00 - val_loss: 0.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5718 - accuracy: 0.0000e+00 - val_loss: 0.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5693 - accuracy: 0.0000e+00 - val_loss: 0.4488 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5668 - accuracy: 0.0000e+00 - val_loss: 0.4465 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5644 - accuracy: 0.0000e+00 - val_loss: 0.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.5620 - accuracy: 0.0000e+00 - val_loss: 0.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5597 - accuracy: 0.0000e+00 - val_loss: 0.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.5573 - accuracy: 0.0000e+00 - val_loss: 0.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5550 - accuracy: 0.0000e+00 - val_loss: 0.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5527 - accuracy: 0.0000e+00 - val_loss: 0.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5504 - accuracy: 0.0000e+00 - val_loss: 0.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5482 - accuracy: 0.0000e+00 - val_loss: 0.4285 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5459 - accuracy: 0.0000e+00 - val_loss: 0.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5437 - accuracy: 0.0000e+00 - val_loss: 0.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5415 - accuracy: 0.0000e+00 - val_loss: 0.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5392 - accuracy: 0.0000e+00 - val_loss: 0.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5370 - accuracy: 0.0000e+00 - val_loss: 0.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5347 - accuracy: 0.0000e+00 - val_loss: 0.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.5325 - accuracy: 0.0000e+00 - val_loss: 0.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.5302 - accuracy: 0.0000e+00 - val_loss: 0.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5278 - accuracy: 0.0000e+00 - val_loss: 0.4089 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5255 - accuracy: 0.0000e+00 - val_loss: 0.4067 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5232 - accuracy: 0.0000e+00 - val_loss: 0.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5209 - accuracy: 0.0000e+00 - val_loss: 0.4023 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5185 - accuracy: 0.0000e+00 - val_loss: 0.4000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5162 - accuracy: 0.0000e+00 - val_loss: 0.3978 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5138 - accuracy: 0.0000e+00 - val_loss: 0.3955 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5114 - accuracy: 0.0000e+00 - val_loss: 0.3932 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5090 - accuracy: 0.0000e+00 - val_loss: 0.3909 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.5066 - accuracy: 0.0000e+00 - val_loss: 0.3885 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5041 - accuracy: 0.0000e+00 - val_loss: 0.3861 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.5017 - accuracy: 0.0000e+00 - val_loss: 0.3837 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4992 - accuracy: 0.0000e+00 - val_loss: 0.3812 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4966 - accuracy: 0.0000e+00 - val_loss: 0.3787 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4942 - accuracy: 0.0000e+00 - val_loss: 0.3761 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4917 - accuracy: 0.0000e+00 - val_loss: 0.3735 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4890 - accuracy: 0.0000e+00 - val_loss: 0.3709 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.4865 - accuracy: 0.0000e+00 - val_loss: 0.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4840 - accuracy: 0.0000e+00 - val_loss: 0.3656 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4813 - accuracy: 0.0000e+00 - val_loss: 0.3629 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.4786 - accuracy: 0.0000e+00 - val_loss: 0.3602 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.4761 - accuracy: 0.0000e+00 - val_loss: 0.3573 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4733 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4707 - accuracy: 0.0000e+00 - val_loss: 0.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.4679 - accuracy: 0.0000e+00 - val_loss: 0.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4652 - accuracy: 0.0000e+00 - val_loss: 0.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.4624 - accuracy: 0.0000e+00 - val_loss: 0.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.4597 - accuracy: 0.0000e+00 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4569 - accuracy: 0.0000e+00 - val_loss: 0.3365 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4542 - accuracy: 0.0000e+00 - val_loss: 0.3334 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4512 - accuracy: 0.0000e+00 - val_loss: 0.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4484 - accuracy: 0.0000e+00 - val_loss: 0.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4456 - accuracy: 0.0000e+00 - val_loss: 0.3245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4425 - accuracy: 0.0000e+00 - val_loss: 0.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4396 - accuracy: 0.0000e+00 - val_loss: 0.3185 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4366 - accuracy: 0.0000e+00 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4337 - accuracy: 0.0000e+00 - val_loss: 0.3123 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.4308 - accuracy: 0.0000e+00 - val_loss: 0.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4277 - accuracy: 0.0000e+00 - val_loss: 0.3061 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4249 - accuracy: 0.0000e+00 - val_loss: 0.3031 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.4218 - accuracy: 0.0000e+00 - val_loss: 0.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4188 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4157 - accuracy: 0.0000e+00 - val_loss: 0.2947 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.4126 - accuracy: 0.0000e+00 - val_loss: 0.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.4094 - accuracy: 0.0000e+00 - val_loss: 0.2895 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.4062 - accuracy: 0.0000e+00 - val_loss: 0.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.4030 - accuracy: 0.0000e+00 - val_loss: 0.2840 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.3996 - accuracy: 0.0000e+00 - val_loss: 0.2814 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3964 - accuracy: 0.0000e+00 - val_loss: 0.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3930 - accuracy: 0.0000e+00 - val_loss: 0.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3896 - accuracy: 0.0000e+00 - val_loss: 0.2741 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3864 - accuracy: 0.0000e+00 - val_loss: 0.2717 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3830 - accuracy: 0.0000e+00 - val_loss: 0.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3797 - accuracy: 0.0000e+00 - val_loss: 0.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3764 - accuracy: 0.0000e+00 - val_loss: 0.2641 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3730 - accuracy: 0.0000e+00 - val_loss: 0.2616 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3699 - accuracy: 0.0000e+00 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3666 - accuracy: 0.0000e+00 - val_loss: 0.2569 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3634 - accuracy: 0.0000e+00 - val_loss: 0.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3599 - accuracy: 0.0000e+00 - val_loss: 0.2525 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3568 - accuracy: 0.0000e+00 - val_loss: 0.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3536 - accuracy: 0.0000e+00 - val_loss: 0.2481 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.3502 - accuracy: 0.0000e+00 - val_loss: 0.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.3470 - accuracy: 0.0000e+00 - val_loss: 0.2437 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3409 - accuracy: 0.0000e+00 - val_loss: 0.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.3377 - accuracy: 0.0000e+00 - val_loss: 0.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.3346 - accuracy: 0.0000e+00 - val_loss: 0.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3316 - accuracy: 0.0000e+00 - val_loss: 0.2339 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3284 - accuracy: 0.0000e+00 - val_loss: 0.2322 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3255 - accuracy: 0.0000e+00 - val_loss: 0.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3227 - accuracy: 0.0000e+00 - val_loss: 0.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.3197 - accuracy: 0.0000e+00 - val_loss: 0.2284 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3169 - accuracy: 0.0000e+00 - val_loss: 0.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.3140 - accuracy: 0.0000e+00 - val_loss: 0.2258 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.3112 - accuracy: 0.0000e+00 - val_loss: 0.2245 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.3083 - accuracy: 0.0000e+00 - val_loss: 0.2237 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3059 - accuracy: 0.0000e+00 - val_loss: 0.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.3030 - accuracy: 0.0000e+00 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.3002 - accuracy: 0.0000e+00 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2977 - accuracy: 0.0000e+00 - val_loss: 0.2205 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.2953 - accuracy: 0.0000e+00 - val_loss: 0.2196 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2928 - accuracy: 0.0000e+00 - val_loss: 0.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.2904 - accuracy: 0.0000e+00 - val_loss: 0.2180 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.0000e+ - 0s 224us/step - loss: 0.2881 - accuracy: 0.0000e+00 - val_loss: 0.2172 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.2859 - accuracy: 0.0000e+00 - val_loss: 0.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2839 - accuracy: 0.0000e+00 - val_loss: 0.2157 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "80/80 [==============================] - 0s 249us/step - loss: 0.2818 - accuracy: 0.0000e+00 - val_loss: 0.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2798 - accuracy: 0.0000e+00 - val_loss: 0.2144 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2780 - accuracy: 0.0000e+00 - val_loss: 0.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2761 - accuracy: 0.0000e+00 - val_loss: 0.2138 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2741 - accuracy: 0.0000e+00 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2721 - accuracy: 0.0000e+00 - val_loss: 0.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2704 - accuracy: 0.0000e+00 - val_loss: 0.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2690 - accuracy: 0.0000e+00 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2669 - accuracy: 0.0000e+00 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2654 - accuracy: 0.0000e+00 - val_loss: 0.2136 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2637 - accuracy: 0.0000e+00 - val_loss: 0.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2622 - accuracy: 0.0000e+00 - val_loss: 0.2138 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2606 - accuracy: 0.0000e+00 - val_loss: 0.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2594 - accuracy: 0.0000e+00 - val_loss: 0.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2579 - accuracy: 0.0000e+00 - val_loss: 0.2140 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2566 - accuracy: 0.0000e+00 - val_loss: 0.2142 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2554 - accuracy: 0.0000e+00 - val_loss: 0.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2544 - accuracy: 0.0000e+00 - val_loss: 0.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2530 - accuracy: 0.0000e+00 - val_loss: 0.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2518 - accuracy: 0.0000e+00 - val_loss: 0.2157 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2508 - accuracy: 0.0000e+00 - val_loss: 0.2161 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2497 - accuracy: 0.0000e+00 - val_loss: 0.2168 - val_accuracy: 0.0500\n",
      "Epoch 153/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2486 - accuracy: 0.0000e+00 - val_loss: 0.2174 - val_accuracy: 0.0500\n",
      "Epoch 154/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2476 - accuracy: 0.0000e+00 - val_loss: 0.2181 - val_accuracy: 0.0500\n",
      "Epoch 155/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2465 - accuracy: 0.0000e+00 - val_loss: 0.2188 - val_accuracy: 0.0500\n",
      "Epoch 156/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2455 - accuracy: 0.0000e+00 - val_loss: 0.2194 - val_accuracy: 0.0500\n",
      "Epoch 157/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2444 - accuracy: 0.0000e+00 - val_loss: 0.2199 - val_accuracy: 0.0500\n",
      "Epoch 158/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2434 - accuracy: 0.0000e+00 - val_loss: 0.2205 - val_accuracy: 0.0500\n",
      "Epoch 159/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2427 - accuracy: 0.0000e+00 - val_loss: 0.2210 - val_accuracy: 0.0500\n",
      "Epoch 160/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2418 - accuracy: 0.0000e+00 - val_loss: 0.2215 - val_accuracy: 0.0500\n",
      "Epoch 161/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2411 - accuracy: 0.0000e+00 - val_loss: 0.2220 - val_accuracy: 0.0500\n",
      "Epoch 162/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2402 - accuracy: 0.0000e+00 - val_loss: 0.2223 - val_accuracy: 0.0500\n",
      "Epoch 163/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2395 - accuracy: 0.0000e+00 - val_loss: 0.2227 - val_accuracy: 0.0500\n",
      "Epoch 164/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2387 - accuracy: 0.0000e+00 - val_loss: 0.2230 - val_accuracy: 0.0500\n",
      "Epoch 165/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2381 - accuracy: 0.0000e+00 - val_loss: 0.2238 - val_accuracy: 0.0500\n",
      "Epoch 166/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2373 - accuracy: 0.0000e+00 - val_loss: 0.2245 - val_accuracy: 0.0500\n",
      "Epoch 167/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2366 - accuracy: 0.0000e+00 - val_loss: 0.2252 - val_accuracy: 0.0500\n",
      "Epoch 168/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.0000e+ - 0s 162us/step - loss: 0.2357 - accuracy: 0.0000e+00 - val_loss: 0.2258 - val_accuracy: 0.0500\n",
      "Epoch 169/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2351 - accuracy: 0.0000e+00 - val_loss: 0.2266 - val_accuracy: 0.0500\n",
      "Epoch 170/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2345 - accuracy: 0.0000e+00 - val_loss: 0.2273 - val_accuracy: 0.0500\n",
      "Epoch 171/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2336 - accuracy: 0.0000e+00 - val_loss: 0.2279 - val_accuracy: 0.0500\n",
      "Epoch 172/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2330 - accuracy: 0.0000e+00 - val_loss: 0.2285 - val_accuracy: 0.0500\n",
      "Epoch 173/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2323 - accuracy: 0.0000e+00 - val_loss: 0.2290 - val_accuracy: 0.0500\n",
      "Epoch 174/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2317 - accuracy: 0.0000e+00 - val_loss: 0.2295 - val_accuracy: 0.0500\n",
      "Epoch 175/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2312 - accuracy: 0.0000e+00 - val_loss: 0.2301 - val_accuracy: 0.0500\n",
      "Epoch 176/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2305 - accuracy: 0.0000e+00 - val_loss: 0.2304 - val_accuracy: 0.0500\n",
      "Epoch 177/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2299 - accuracy: 0.0000e+00 - val_loss: 0.2307 - val_accuracy: 0.0500\n",
      "Epoch 178/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2294 - accuracy: 0.0000e+00 - val_loss: 0.2310 - val_accuracy: 0.0500\n",
      "Epoch 179/400\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.2289 - accuracy: 0.0000e+00 - val_loss: 0.2313 - val_accuracy: 0.0500\n",
      "Epoch 180/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2284 - accuracy: 0.0000e+00 - val_loss: 0.2315 - val_accuracy: 0.0500\n",
      "Epoch 181/400\n",
      "80/80 [==============================] - 0s 162us/step - loss: 0.2278 - accuracy: 0.0000e+00 - val_loss: 0.2317 - val_accuracy: 0.0500\n",
      "Epoch 182/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2274 - accuracy: 0.0000e+00 - val_loss: 0.2319 - val_accuracy: 0.0500\n",
      "Epoch 183/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2268 - accuracy: 0.0000e+00 - val_loss: 0.2321 - val_accuracy: 0.0500\n",
      "Epoch 184/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2263 - accuracy: 0.0000e+00 - val_loss: 0.2323 - val_accuracy: 0.0500\n",
      "Epoch 185/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2258 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 186/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2253 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 187/400\n",
      "80/80 [==============================] - 0s 174us/step - loss: 0.2248 - accuracy: 0.0000e+00 - val_loss: 0.2328 - val_accuracy: 0.0500\n",
      "Epoch 188/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2243 - accuracy: 0.0000e+00 - val_loss: 0.2328 - val_accuracy: 0.0500\n",
      "Epoch 189/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2238 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 190/400\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.2233 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 191/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2228 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 192/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2223 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 193/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2218 - accuracy: 0.0000e+00 - val_loss: 0.2325 - val_accuracy: 0.0500\n",
      "Epoch 194/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2212 - accuracy: 0.0000e+00 - val_loss: 0.2325 - val_accuracy: 0.0500\n",
      "Epoch 195/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2208 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 196/400\n",
      "80/80 [==============================] - 0s 175us/step - loss: 0.2202 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 197/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2196 - accuracy: 0.0000e+00 - val_loss: 0.2328 - val_accuracy: 0.0500\n",
      "Epoch 198/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2190 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 199/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2185 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 200/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2179 - accuracy: 0.0000e+00 - val_loss: 0.2326 - val_accuracy: 0.0500\n",
      "Epoch 201/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2173 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 202/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2167 - accuracy: 0.0000e+00 - val_loss: 0.2329 - val_accuracy: 0.0500\n",
      "Epoch 203/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2161 - accuracy: 0.0000e+00 - val_loss: 0.2329 - val_accuracy: 0.0500\n",
      "Epoch 204/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2154 - accuracy: 0.0000e+00 - val_loss: 0.2327 - val_accuracy: 0.0500\n",
      "Epoch 205/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2148 - accuracy: 0.0000e+00 - val_loss: 0.2325 - val_accuracy: 0.0500\n",
      "Epoch 206/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2141 - accuracy: 0.0000e+00 - val_loss: 0.2323 - val_accuracy: 0.0500\n",
      "Epoch 207/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2135 - accuracy: 0.0000e+00 - val_loss: 0.2321 - val_accuracy: 0.0500\n",
      "Epoch 208/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2128 - accuracy: 0.0000e+00 - val_loss: 0.2317 - val_accuracy: 0.0500\n",
      "Epoch 209/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2122 - accuracy: 0.0000e+00 - val_loss: 0.2312 - val_accuracy: 0.0500\n",
      "Epoch 210/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2114 - accuracy: 0.0000e+00 - val_loss: 0.2306 - val_accuracy: 0.0500\n",
      "Epoch 211/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2107 - accuracy: 0.0000e+00 - val_loss: 0.2300 - val_accuracy: 0.0500\n",
      "Epoch 212/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2100 - accuracy: 0.0000e+00 - val_loss: 0.2293 - val_accuracy: 0.0500\n",
      "Epoch 213/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2093 - accuracy: 0.0000e+00 - val_loss: 0.2287 - val_accuracy: 0.0500\n",
      "Epoch 214/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2085 - accuracy: 0.0000e+00 - val_loss: 0.2279 - val_accuracy: 0.0500\n",
      "Epoch 215/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2078 - accuracy: 0.0000e+00 - val_loss: 0.2272 - val_accuracy: 0.0500\n",
      "Epoch 216/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2070 - accuracy: 0.0000e+00 - val_loss: 0.2265 - val_accuracy: 0.0500\n",
      "Epoch 217/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2062 - accuracy: 0.0000e+00 - val_loss: 0.2259 - val_accuracy: 0.0500\n",
      "Epoch 218/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.2053 - accuracy: 0.0000e+00 - val_loss: 0.2253 - val_accuracy: 0.0500\n",
      "Epoch 219/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2045 - accuracy: 0.0000e+00 - val_loss: 0.2250 - val_accuracy: 0.0500\n",
      "Epoch 220/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2036 - accuracy: 0.0000e+00 - val_loss: 0.2245 - val_accuracy: 0.0500\n",
      "Epoch 221/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2027 - accuracy: 0.0000e+00 - val_loss: 0.2240 - val_accuracy: 0.0500\n",
      "Epoch 222/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.2019 - accuracy: 0.0000e+00 - val_loss: 0.2234 - val_accuracy: 0.0500\n",
      "Epoch 223/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.2009 - accuracy: 0.0000e+00 - val_loss: 0.2228 - val_accuracy: 0.0500\n",
      "Epoch 224/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.2000 - accuracy: 0.0000e+00 - val_loss: 0.2222 - val_accuracy: 0.0500\n",
      "Epoch 225/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.1990 - accuracy: 0.0000e+00 - val_loss: 0.2216 - val_accuracy: 0.0500\n",
      "Epoch 226/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.1981 - accuracy: 0.0000e+00 - val_loss: 0.2209 - val_accuracy: 0.0500\n",
      "Epoch 227/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1970 - accuracy: 0.0000e+00 - val_loss: 0.2198 - val_accuracy: 0.0500\n",
      "Epoch 228/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1960 - accuracy: 0.0000e+00 - val_loss: 0.2188 - val_accuracy: 0.0500\n",
      "Epoch 229/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1949 - accuracy: 0.0000e+00 - val_loss: 0.2176 - val_accuracy: 0.0500\n",
      "Epoch 230/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1939 - accuracy: 0.0000e+00 - val_loss: 0.2166 - val_accuracy: 0.0500\n",
      "Epoch 231/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1927 - accuracy: 0.0000e+00 - val_loss: 0.2155 - val_accuracy: 0.0500\n",
      "Epoch 232/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1916 - accuracy: 0.0000e+00 - val_loss: 0.2144 - val_accuracy: 0.0500\n",
      "Epoch 233/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.2134 - val_accuracy: 0.0500\n",
      "Epoch 234/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1893 - accuracy: 0.0000e+00 - val_loss: 0.2122 - val_accuracy: 0.0500\n",
      "Epoch 235/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1881 - accuracy: 0.0000e+00 - val_loss: 0.2110 - val_accuracy: 0.0500\n",
      "Epoch 236/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1869 - accuracy: 0.0000e+00 - val_loss: 0.2100 - val_accuracy: 0.0500\n",
      "Epoch 237/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1856 - accuracy: 0.0000e+00 - val_loss: 0.2087 - val_accuracy: 0.0500\n",
      "Epoch 238/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1843 - accuracy: 0.0000e+00 - val_loss: 0.2075 - val_accuracy: 0.0500\n",
      "Epoch 239/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1830 - accuracy: 0.0000e+00 - val_loss: 0.2063 - val_accuracy: 0.0500\n",
      "Epoch 240/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1817 - accuracy: 0.0000e+00 - val_loss: 0.2049 - val_accuracy: 0.0500\n",
      "Epoch 241/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1802 - accuracy: 0.0000e+00 - val_loss: 0.2032 - val_accuracy: 0.0500\n",
      "Epoch 242/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1788 - accuracy: 0.0000e+00 - val_loss: 0.2015 - val_accuracy: 0.0500\n",
      "Epoch 243/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.1773 - accuracy: 0.0000e+00 - val_loss: 0.1998 - val_accuracy: 0.0500\n",
      "Epoch 244/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.1759 - accuracy: 0.0000e+00 - val_loss: 0.1982 - val_accuracy: 0.0500\n",
      "Epoch 245/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1743 - accuracy: 0.0000e+00 - val_loss: 0.1962 - val_accuracy: 0.0500\n",
      "Epoch 246/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1727 - accuracy: 0.0000e+00 - val_loss: 0.1942 - val_accuracy: 0.0500\n",
      "Epoch 247/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1712 - accuracy: 0.0000e+00 - val_loss: 0.1918 - val_accuracy: 0.0500\n",
      "Epoch 248/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1695 - accuracy: 0.0000e+00 - val_loss: 0.1896 - val_accuracy: 0.0500\n",
      "Epoch 249/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1678 - accuracy: 0.0000e+00 - val_loss: 0.1874 - val_accuracy: 0.0500\n",
      "Epoch 250/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1661 - accuracy: 0.0000e+00 - val_loss: 0.1853 - val_accuracy: 0.0500\n",
      "Epoch 251/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.1644 - accuracy: 0.0000e+00 - val_loss: 0.1833 - val_accuracy: 0.0500\n",
      "Epoch 252/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1626 - accuracy: 0.0000e+00 - val_loss: 0.1812 - val_accuracy: 0.0500\n",
      "Epoch 253/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1607 - accuracy: 0.0000e+00 - val_loss: 0.1788 - val_accuracy: 0.0500\n",
      "Epoch 254/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1589 - accuracy: 0.0000e+00 - val_loss: 0.1764 - val_accuracy: 0.0500\n",
      "Epoch 255/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1569 - accuracy: 0.0000e+00 - val_loss: 0.1742 - val_accuracy: 0.0500\n",
      "Epoch 256/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1550 - accuracy: 0.0000e+00 - val_loss: 0.1716 - val_accuracy: 0.0500\n",
      "Epoch 257/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1529 - accuracy: 0.0000e+00 - val_loss: 0.1690 - val_accuracy: 0.0500\n",
      "Epoch 258/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1509 - accuracy: 0.0000e+00 - val_loss: 0.1661 - val_accuracy: 0.0500\n",
      "Epoch 259/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1487 - accuracy: 0.0000e+00 - val_loss: 0.1633 - val_accuracy: 0.0500\n",
      "Epoch 260/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1466 - accuracy: 0.0000e+00 - val_loss: 0.1604 - val_accuracy: 0.0500\n",
      "Epoch 261/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1444 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0500\n",
      "Epoch 262/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1421 - accuracy: 0.0000e+00 - val_loss: 0.1547 - val_accuracy: 0.0500\n",
      "Epoch 263/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1399 - accuracy: 0.0000e+00 - val_loss: 0.1518 - val_accuracy: 0.0500\n",
      "Epoch 264/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1375 - accuracy: 0.0000e+00 - val_loss: 0.1489 - val_accuracy: 0.0500\n",
      "Epoch 265/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1351 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0500\n",
      "Epoch 266/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1328 - accuracy: 0.0000e+00 - val_loss: 0.1434 - val_accuracy: 0.0500\n",
      "Epoch 267/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1302 - accuracy: 0.0000e+00 - val_loss: 0.1404 - val_accuracy: 0.0500\n",
      "Epoch 268/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1278 - accuracy: 0.0000e+00 - val_loss: 0.1372 - val_accuracy: 0.0500\n",
      "Epoch 269/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1252 - accuracy: 0.0000e+00 - val_loss: 0.1339 - val_accuracy: 0.0500\n",
      "Epoch 270/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.1226 - accuracy: 0.0000e+00 - val_loss: 0.1308 - val_accuracy: 0.0500\n",
      "Epoch 271/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1200 - accuracy: 0.0000e+00 - val_loss: 0.1275 - val_accuracy: 0.0500\n",
      "Epoch 272/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1173 - accuracy: 0.0000e+00 - val_loss: 0.1243 - val_accuracy: 0.0500\n",
      "Epoch 273/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.1146 - accuracy: 0.0000e+00 - val_loss: 0.1213 - val_accuracy: 0.0500\n",
      "Epoch 274/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1118 - accuracy: 0.0000e+00 - val_loss: 0.1181 - val_accuracy: 0.0500\n",
      "Epoch 275/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.1090 - accuracy: 0.0000e+00 - val_loss: 0.1149 - val_accuracy: 0.0500\n",
      "Epoch 276/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1062 - accuracy: 0.0000e+00 - val_loss: 0.1115 - val_accuracy: 0.0500\n",
      "Epoch 277/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.1033 - accuracy: 0.0000e+00 - val_loss: 0.1078 - val_accuracy: 0.0500\n",
      "Epoch 278/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.1004 - accuracy: 0.0000e+00 - val_loss: 0.1043 - val_accuracy: 0.0500\n",
      "Epoch 279/400\n",
      "80/80 [==============================] - 0s 225us/step - loss: 0.0975 - accuracy: 0.0000e+00 - val_loss: 0.1005 - val_accuracy: 0.0500\n",
      "Epoch 280/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0945 - accuracy: 0.0000e+00 - val_loss: 0.0973 - val_accuracy: 0.0500\n",
      "Epoch 281/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0914 - accuracy: 0.0000e+00 - val_loss: 0.0938 - val_accuracy: 0.0500\n",
      "Epoch 282/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0884 - accuracy: 0.0000e+00 - val_loss: 0.0902 - val_accuracy: 0.0500\n",
      "Epoch 283/400\n",
      "80/80 [==============================] - 0s 374us/step - loss: 0.0853 - accuracy: 0.0000e+00 - val_loss: 0.0867 - val_accuracy: 0.0500\n",
      "Epoch 284/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0821 - accuracy: 0.0000e+00 - val_loss: 0.0831 - val_accuracy: 0.0500\n",
      "Epoch 285/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0792 - accuracy: 0.0000e+00 - val_loss: 0.0792 - val_accuracy: 0.0500\n",
      "Epoch 286/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0759 - accuracy: 0.0000e+00 - val_loss: 0.0757 - val_accuracy: 0.0500\n",
      "Epoch 287/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0728 - accuracy: 0.0000e+00 - val_loss: 0.0719 - val_accuracy: 0.0500\n",
      "Epoch 288/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0696 - accuracy: 0.0000e+00 - val_loss: 0.0680 - val_accuracy: 0.0500\n",
      "Epoch 289/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0663 - accuracy: 0.0000e+00 - val_loss: 0.0642 - val_accuracy: 0.0500\n",
      "Epoch 290/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0631 - accuracy: 0.0000e+00 - val_loss: 0.0605 - val_accuracy: 0.0500\n",
      "Epoch 291/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0600 - accuracy: 0.0000e+00 - val_loss: 0.0567 - val_accuracy: 0.0500\n",
      "Epoch 292/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0569 - accuracy: 0.0000e+00 - val_loss: 0.0545 - val_accuracy: 0.0500\n",
      "Epoch 293/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0540 - accuracy: 0.0000e+00 - val_loss: 0.0530 - val_accuracy: 0.0500\n",
      "Epoch 294/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0520 - accuracy: 0.0000e+00 - val_loss: 0.0517 - val_accuracy: 0.0500\n",
      "Epoch 295/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0498 - accuracy: 0.0000e+00 - val_loss: 0.0499 - val_accuracy: 0.0500\n",
      "Epoch 296/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0481 - accuracy: 0.0000e+00 - val_loss: 0.0487 - val_accuracy: 0.0500\n",
      "Epoch 297/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0468 - accuracy: 0.0000e+00 - val_loss: 0.0477 - val_accuracy: 0.0500\n",
      "Epoch 298/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0459 - accuracy: 0.0000e+00 - val_loss: 0.0470 - val_accuracy: 0.0500\n",
      "Epoch 299/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0451 - accuracy: 0.0000e+00 - val_loss: 0.0465 - val_accuracy: 0.0500\n",
      "Epoch 300/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0443 - accuracy: 0.0000e+00 - val_loss: 0.0461 - val_accuracy: 0.0500\n",
      "Epoch 301/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0437 - accuracy: 0.0000e+00 - val_loss: 0.0458 - val_accuracy: 0.0500\n",
      "Epoch 302/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0433 - accuracy: 0.0000e+00 - val_loss: 0.0456 - val_accuracy: 0.0500\n",
      "Epoch 303/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0429 - accuracy: 0.0000e+00 - val_loss: 0.0455 - val_accuracy: 0.0500\n",
      "Epoch 304/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0426 - accuracy: 0.0000e+00 - val_loss: 0.0453 - val_accuracy: 0.0500\n",
      "Epoch 305/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0423 - accuracy: 0.0000e+00 - val_loss: 0.0452 - val_accuracy: 0.0500\n",
      "Epoch 306/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0421 - accuracy: 0.0000e+00 - val_loss: 0.0451 - val_accuracy: 0.0500\n",
      "Epoch 307/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0420 - accuracy: 0.0000e+00 - val_loss: 0.0450 - val_accuracy: 0.0500\n",
      "Epoch 308/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0417 - accuracy: 0.0000e+00 - val_loss: 0.0448 - val_accuracy: 0.0500\n",
      "Epoch 309/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0416 - accuracy: 0.0000e+00 - val_loss: 0.0447 - val_accuracy: 0.0500\n",
      "Epoch 310/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0415 - accuracy: 0.0000e+00 - val_loss: 0.0446 - val_accuracy: 0.0500\n",
      "Epoch 311/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0415 - accuracy: 0.0000e+00 - val_loss: 0.0445 - val_accuracy: 0.0500\n",
      "Epoch 312/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0414 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0500\n",
      "Epoch 313/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0413 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0500\n",
      "Epoch 314/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0412 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0500\n",
      "Epoch 315/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0411 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0500\n",
      "Epoch 316/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0410 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0500\n",
      "Epoch 317/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0410 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0500\n",
      "Epoch 318/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0409 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0500\n",
      "Epoch 319/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0408 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0500\n",
      "Epoch 320/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0408 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 321/400\n",
      "80/80 [==============================] - 0s 200us/step - loss: 0.0407 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 322/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0407 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 323/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0406 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 324/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0405 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0500\n",
      "Epoch 325/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0404 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0500\n",
      "Epoch 326/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0404 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0500\n",
      "Epoch 327/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.0000e+ - 0s 199us/step - loss: 0.0403 - accuracy: 0.0000e+00 - val_loss: 0.0442 - val_accuracy: 0.0500\n",
      "Epoch 328/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0403 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0500\n",
      "Epoch 329/400\n",
      "80/80 [==============================] - 0s 187us/step - loss: 0.0402 - accuracy: 0.0000e+00 - val_loss: 0.0445 - val_accuracy: 0.0500\n",
      "Epoch 330/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0402 - accuracy: 0.0000e+00 - val_loss: 0.0444 - val_accuracy: 0.0500\n",
      "Epoch 331/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0401 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0500\n",
      "Epoch 332/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0400 - accuracy: 0.0000e+00 - val_loss: 0.0441 - val_accuracy: 0.0500\n",
      "Epoch 333/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.0400 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 334/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0399 - accuracy: 0.0000e+00 - val_loss: 0.0439 - val_accuracy: 0.0500\n",
      "Epoch 335/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0399 - accuracy: 0.0000e+00 - val_loss: 0.0440 - val_accuracy: 0.0500\n",
      "Epoch 336/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0398 - accuracy: 0.0000e+00 - val_loss: 0.0438 - val_accuracy: 0.0500\n",
      "Epoch 337/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0397 - accuracy: 0.0000e+00 - val_loss: 0.0436 - val_accuracy: 0.0500\n",
      "Epoch 338/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0397 - accuracy: 0.0000e+00 - val_loss: 0.0434 - val_accuracy: 0.0500\n",
      "Epoch 339/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0397 - accuracy: 0.0000e+00 - val_loss: 0.0432 - val_accuracy: 0.0500\n",
      "Epoch 340/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0396 - accuracy: 0.0000e+00 - val_loss: 0.0431 - val_accuracy: 0.0500\n",
      "Epoch 341/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0396 - accuracy: 0.0000e+00 - val_loss: 0.0430 - val_accuracy: 0.0500\n",
      "Epoch 342/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0396 - accuracy: 0.0000e+00 - val_loss: 0.0430 - val_accuracy: 0.0500\n",
      "Epoch 343/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0395 - accuracy: 0.0000e+00 - val_loss: 0.0429 - val_accuracy: 0.0500\n",
      "Epoch 344/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.0394 - accuracy: 0.0000e+00 - val_loss: 0.0430 - val_accuracy: 0.0500\n",
      "Epoch 345/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0393 - accuracy: 0.0000e+00 - val_loss: 0.0432 - val_accuracy: 0.0500\n",
      "Epoch 346/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0392 - accuracy: 0.0000e+00 - val_loss: 0.0434 - val_accuracy: 0.0500\n",
      "Epoch 347/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0392 - accuracy: 0.0000e+00 - val_loss: 0.0436 - val_accuracy: 0.0500\n",
      "Epoch 348/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0393 - accuracy: 0.0000e+00 - val_loss: 0.0438 - val_accuracy: 0.0500\n",
      "Epoch 349/400\n",
      "80/80 [==============================] - 0s 324us/step - loss: 0.0392 - accuracy: 0.0000e+00 - val_loss: 0.0437 - val_accuracy: 0.0500\n",
      "Epoch 350/400\n",
      "80/80 [==============================] - 0s 424us/step - loss: 0.0391 - accuracy: 0.0000e+00 - val_loss: 0.0435 - val_accuracy: 0.0500\n",
      "Epoch 351/400\n",
      "80/80 [==============================] - 0s 312us/step - loss: 0.0391 - accuracy: 0.0000e+00 - val_loss: 0.0433 - val_accuracy: 0.0500\n",
      "Epoch 352/400\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.0390 - accuracy: 0.0000e+00 - val_loss: 0.0431 - val_accuracy: 0.0500\n",
      "Epoch 353/400\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0429 - val_accuracy: 0.0500\n",
      "Epoch 354/400\n",
      "80/80 [==============================] - 0s 299us/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0500\n",
      "Epoch 355/400\n",
      "80/80 [==============================] - 0s 286us/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0500\n",
      "Epoch 356/400\n",
      "80/80 [==============================] - 0s 274us/step - loss: 0.0388 - accuracy: 0.0000e+00 - val_loss: 0.0426 - val_accuracy: 0.0500\n",
      "Epoch 357/400\n",
      "80/80 [==============================] - 0s 262us/step - loss: 0.0388 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0500\n",
      "Epoch 358/400\n",
      "80/80 [==============================] - 0s 287us/step - loss: 0.0387 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0500\n",
      "Epoch 359/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0387 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0500\n",
      "Epoch 360/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0386 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0500\n",
      "Epoch 361/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0386 - accuracy: 0.0000e+00 - val_loss: 0.0428 - val_accuracy: 0.0500\n",
      "Epoch 362/400\n",
      "80/80 [==============================] - 0s 237us/step - loss: 0.0385 - accuracy: 0.0000e+00 - val_loss: 0.0427 - val_accuracy: 0.0500\n",
      "Epoch 363/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0385 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0500\n",
      "Epoch 364/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0384 - accuracy: 0.0000e+00 - val_loss: 0.0423 - val_accuracy: 0.0500\n",
      "Epoch 365/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0384 - accuracy: 0.0000e+00 - val_loss: 0.0423 - val_accuracy: 0.0500\n",
      "Epoch 366/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0423 - val_accuracy: 0.0500\n",
      "Epoch 367/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0424 - val_accuracy: 0.0500\n",
      "Epoch 368/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0382 - accuracy: 0.0000e+00 - val_loss: 0.0424 - val_accuracy: 0.0500\n",
      "Epoch 369/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0382 - accuracy: 0.0000e+00 - val_loss: 0.0422 - val_accuracy: 0.0500\n",
      "Epoch 370/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0422 - val_accuracy: 0.0500\n",
      "Epoch 371/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0500\n",
      "Epoch 372/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0500\n",
      "Epoch 373/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0500\n",
      "Epoch 374/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0421 - val_accuracy: 0.0500\n",
      "Epoch 375/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0423 - val_accuracy: 0.0500\n",
      "Epoch 376/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0423 - val_accuracy: 0.0500\n",
      "Epoch 377/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0422 - val_accuracy: 0.0500\n",
      "Epoch 378/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0500\n",
      "Epoch 379/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0377 - accuracy: 0.0000e+00 - val_loss: 0.0419 - val_accuracy: 0.0500\n",
      "Epoch 380/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0377 - accuracy: 0.0000e+00 - val_loss: 0.0417 - val_accuracy: 0.0500\n",
      "Epoch 381/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0377 - accuracy: 0.0000e+00 - val_loss: 0.0417 - val_accuracy: 0.0500\n",
      "Epoch 382/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0376 - accuracy: 0.0000e+00 - val_loss: 0.0418 - val_accuracy: 0.0500\n",
      "Epoch 383/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0376 - accuracy: 0.0000e+00 - val_loss: 0.0417 - val_accuracy: 0.0500\n",
      "Epoch 384/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0375 - accuracy: 0.0000e+00 - val_loss: 0.0416 - val_accuracy: 0.0500\n",
      "Epoch 385/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0375 - accuracy: 0.0000e+00 - val_loss: 0.0414 - val_accuracy: 0.0500\n",
      "Epoch 386/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0375 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 387/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0374 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 388/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0374 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 389/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0374 - accuracy: 0.0000e+00 - val_loss: 0.0415 - val_accuracy: 0.0500\n",
      "Epoch 390/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0373 - accuracy: 0.0000e+00 - val_loss: 0.0416 - val_accuracy: 0.0500\n",
      "Epoch 391/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0373 - accuracy: 0.0000e+00 - val_loss: 0.0415 - val_accuracy: 0.0500\n",
      "Epoch 392/400\n",
      "80/80 [==============================] - 0s 212us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0414 - val_accuracy: 0.0500\n",
      "Epoch 393/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0413 - val_accuracy: 0.0500\n",
      "Epoch 394/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 395/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 396/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0412 - val_accuracy: 0.0500\n",
      "Epoch 397/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0411 - val_accuracy: 0.0500\n",
      "Epoch 398/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0411 - val_accuracy: 0.0500\n",
      "Epoch 399/400\n",
      "80/80 [==============================] - 0s 199us/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0408 - val_accuracy: 0.0500\n",
      "Epoch 400/400\n",
      "80/80 [==============================] - 0s 224us/step - loss: 0.0369 - accuracy: 0.0000e+00 - val_loss: 0.0407 - val_accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "#Train le modèle pendant un nombre fixe d'epochs et détermine les données utilisées pour valider la loss comme x_test et y_test\n",
    "history = model.fit(x_train,y_train,epochs=400,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On crée une output prediction de l'input pour la comparer à notre résultat\n",
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXpUlEQVR4nO3dfYxjV3nH8e8zySzIBCZsdtvSbGyHKlRdurSEUUqhBaqJ6GbV3bQVQokuakoAC7VpCS9VU7niJZX/4KVtaJVCXQoE5JIE2tBdFLTANgUJNTSzEDKEkLKk48k2KVmSMGlrtTubffrHvbN4vPaMx3Pt6+vz+0gr28fX40d37vz2+J7jc83dERGRyTeVdQEiIjIaCnwRkUAo8EVEAqHAFxEJhAJfRCQQ52b1xjt27PByuZzV24uI5NLRo0d/4O47B3ltZoFfLpeZn5/P6u1FRHLJzJqDvlandEREAqHAFxEJhAJfRCQQCnwRkUAo8EVEAqHAFxEJhAJfRCQQCnwRkUAo8GWkGgsNyjeVmXrPFOWbyjQWGlmXJBKMzL5pK+FpLDSoHKrQWmkB0FxuUjlUASDaE2VZmkgQ1MMfkHqqm1c9Uj0T9qtaKy2qR6oZVSQSlg0D38w+amaPmdm3ejxvZvYXZnbMzO4zs0vTL3O8rPZUm8tNHD/TU1Xor29peWlT7SKSrn56+B8H9q7z/BXAJcm/CvChrZc13tRTHUxxpripdllLnyplqzYMfHf/CvDEOptcCXzCY3cD55vZ89IqcByppzqY2lyNwnRhTVthukBtrpZRRfmhT5WShjTO4V8IPNz2+HjSNrHUUx1MtCeivr9OaaaEYZRmStT31zVg2wd9qpQ0pDFLx7q0edcNzSrEp30oFvMbjrW52prZJqCear+iPZECfgD6VClpSKOHfxy4qO3xLuCRbhu6e93dZ919dufOgS7YMhbUU5VR06dKSUMaPfyDwHVmdivwC8Cyuz+aws8da+qpyijpU6WkYcPAN7NPAa8CdpjZceBdwDSAu38YuBPYBxwDWsDrh1WsSKhWOxfVI1WWlpcozhSpzdXU6ZBNMfeup9uHbnZ21nVNWxGRzTGzo+4+O8hr9U1bEZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCYQCX0ar0YByGaam4ttGI+uKRIKhwB+UgmvzGg2oVKDZBPf4tlLRvuuXjjnZIl3xahCrwdX60fVFKRSgXodIl5zrqVyOQ75TqQSLi6OuJl90zEliK1e8UuAPQsE1mKmpuGffyQxOnx59PXmiY04SusThqC0tba5dYsXi5trlR3TMSQoU+INQcA2mVotPQ7QrFOJ2WZ+OOUmBAn8QCq7BRFF8zrlUik/jlEo6B90vHXOSAgX+IBRcg4ui+Jzz6dPxrfZZf3TMSQo0aCsikiMatBURkQ0p8EVEAqHAFxEJhAJfRCQQCnwRkUAo8EVEAqHAFxEJhAJfRCQQfQW+me01swfN7JiZ3dDl+aKZ3WVm3zCz+8xsX/qliojIVmwY+GZ2DnAzcAWwG7jazHZ3bPbHwO3u/mLgKuCv0i5URES2pp8e/mXAMXd/yN1PArcCV3Zs48BzkvszwCPplSgiImnoJ/AvBB5ue3w8aWv3buB1ZnYcuBP4vW4/yMwqZjZvZvMnTpwYoFwRERlUP4FvXdo6V1y7Gvi4u+8C9gGfNLOzfra719191t1nd+7cuflqRURkYP0E/nHgorbHuzj7lM0bgNsB3P1fgGcCO9IoUERE0tFP4N8DXGJmF5vZNuJB2YMd2ywBcwBm9jPEga9zNiIiY2TDwHf3U8B1wGHgAeLZOPeb2Y1mdiDZ7O3Am8zsm8CngN/2rBbaFxGRrs7tZyN3v5N4MLa97Z1t978NvDzd0kREJE36pq2ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDg51GjAeUyTE3Ft41G1hWJSA70tZaOjJFGAyoVaLXix81m/BggirKrS0TGnnr4eVOt/ijsV7VacbuIyDoU+HmztLS5dhGRhAI/b4rFzbWLiCQU+HlTq0GhsLatUIjbRUTWoUHbvIkiGk99lepDdZae9TTF/zmH2vOvIdKArYhsQD38nGksNKg8eQvN857GDZrnPU3lyVtoLGhqpoisT4GfM9UjVVora2fptFZaVI9olo6IrE+BnzNLy91n4/RqFxFZpcDPmeJM99k4vdpFRFYp8HOmNlejML12lk5hukBtTrN0RGR9CvycifZE1PfXKc2UMIzSTIn6/jrRHs3SEZH1mbtn8sazs7M+Pz+fyXuLiOSVmR1199lBXqsevohIIBT4IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiARCgS8iMkyNBpTLMDUV3zayW9m2r8A3s71m9qCZHTOzG3ps81oz+7aZ3W9mf5dumSIiOdRoQKUCzSa4x7eVSmahv2Hgm9k5wM3AFcBu4Goz292xzSXAHwEvd/cXAtcPoVYZB2PUWxEZe9UqtNYuZ06rFbdnoJ8e/mXAMXd/yN1PArcCV3Zs8ybgZnd/EsDdH0u3TBkLY9ZbERl7S0s09kD5eph6V3zb2BO3Z6GfwL8QeLjt8fGkrd0LgBeY2VfN7G4z29vtB5lZxczmzWz+xIkTg1Us2Rmz3orIuGu8cjuV/dA8n/gKdedDZX/cnoV+At+6tHWuuHYucAnwKuBq4CNmdv5ZL3Kvu/usu8/u3Llzs7VK1sastyIy7qqXQ2vb2rbWtrg9C/1cxPw4cFHb413AI122udvdV4B/N7MHif8DuCeVKmUsNF65ncrLHj9zAK/2VrhgO1qcWeRsS6ee2FT7sPXTw78HuMTMLjazbcBVwMGObT4L/AqAme0gPsXzUJqFSvbGrbciMu7G7Qp1Gwa+u58CrgMOAw8At7v7/WZ2o5kdSDY7DDxuZt8G7gL+wN0fH1bRko1x662IjLtxu0JdP6d0cPc7gTs72t7Zdt+BtyX/ZEIVZ4o0l5td20XkbKtXoqseqbK0vERxpkhtrpbZFer6CnwRiHsrlUMVWis/mqmj6+mKrC/aE43NJUi1tIL0TdfTFck3XdNWRCRHdE1bERHZkAJfRCQQCnwRkUAo8EVEAqHAl6A0FhqUbyoz9Z4pyjeVaSxopU8Jh+bhSzAaCw0qd1xLy08C0FxuUrnjWgBNLZUgqIcvwagefMuZsF/V8pNUD74lo4pERkuBL8FYWum+vFOvdpFJo8CXYBSXN9cuMmkU+BKM2r0XUFh7RofCybhdJAQKfAlG9MYPUj88TemHYA6lH0L98DTRGz+YdWkiI6FZOhKOKCIComo1vixjsQi1GkSaoSNhUA9fwhJFsLgIp0/Ht5sIe83hl7xTD1+kD42FxpprATSXm1QOVQDN4Zf8UA9fpA/VI9U1F34BaK20qB6pZlSRyOYp8EX6sLS8tKl2kXGkwJdcyeo8evHc7ZtqFxlHCnzJjdXz6M3lJo6fOY8+itCvfYnuc/i/NPS3FkmNAl9yI8vz6NGXn6B+iLVz+A/F7SJ5oVk6khuZnkcvFokWmkQLHe2l4vDfWyQl6uFLbhRnuodrr/ZU1WpQKKxtKxTidpGcUOBLbtSesY/Cytq2wkrcPnRRBPU6lEpgFt/W6/qWruSKuXsmbzw7O+vz8/OZvLfkVLlM4zlNqnOwNBOvclk7AtFTpfhbsyIBMLOj7j47yGt1Dl/yY2mJyDn7PLppLrxIP3RKR/Kj2ONcfa92GRtah2g8KPAlPzRwmktZfn9C1lLgS35o4DSXtA7R+NA5fMmXKFLA54zWIRofffXwzWyvmT1oZsfM7IZ1tnuNmbmZDTSCLCKTJ9PvT8gaGwa+mZ0D3AxcAewGrjaz3V22ezbw+8DX0i5SRPKrNlejYNvWtBVsG7W5fIy9TNKAcz89/MuAY+7+kLufBG4Fruyy3Z8A7wP+N8X6RCTnovugftDXrkN00Inuy7qyjU3agHM/gX8h8HDb4+NJ2xlm9mLgInf/XIq1icgkqFaJjq6weBOcfg8s3gTR0RWojv+g7aQNOPcT+Nal7czXc81sCvhz4O0b/iCzipnNm9n8iRMn+q9SRPJrqcfgbK/2MTJpA879BP5x4KK2x7uAR9oePxv4WeCfzWwReClwsNvArbvX3X3W3Wd37tw5eNUikh85/sLcpA049xP49wCXmNnFZrYNuAo4uPqkuy+7+w53L7t7GbgbOODuWihHRHL9hbm8Dzh32jDw3f0UcB1wGHgAuN3d7zezG83swLALFJGcy/EX5vI84NyNVssUEemlXIZm8+z2UnYrtG5ltUwtrSAi0kuOB5y7UeCLiPSS4wHnbhT4IiK95HjAuRsFvohILzkecO5GgS8iE23La+FEUTxAe/p0fJvTsActjywiE2x1LZzV5RFW18IBiPbkN7gHpR6+iEysSVsLZ6sU+CIysSZtLZytUuCLyMSatLVwtkqBLyITa9LWwtkqBb5IACbpqk2bMWlr4WyV1tIRmXCdM1UACtMF6vvrkz9TZQzXwtkqraUjIj0FPVNlwtbC2SoFvsiEC3qmyoSthbNVCvwAhXo+N1RBz1SZsLVwtkqBH5jV87nN5SaOn/nmoUJ/ctWesY/Cytq2wkrcPvEmbC2crdKgbWDKN5VpLp89iFWaKbF4/eLoC5LhK5dpPKdJdQ6WZqC4DLUjED2V34HLkG1l0FZr6QQm6PO5oVpaInKIFjraTb/z0OiUTmCK527fVLtMAA1cSkKBH5jal6Bwcm1b4WTcLhNKA5eSUOAHJvryE9QPsfabh4fidplQGriUhAZtQzOB3zwUCUmQ37TVXPIB6eO9SLByGfiNhQaVO65dO5f8jmsV+v3Qx3uRYOXylE65toPmqcfPai+dewGL1R9stTQRkbEV3CmdpZWzw369dhERyWngF5c31y4iIjkN/Nq9F3SfS37vBdkUtFmNRjxbZmoqvm1o7EFEhi+XgR+98YPUD0+vnUt+eJrojR/MurSNNRpQqcRTI93j20pFoS8iQ5fLwCeKiN76MRbvKHH6RmPxjhLRWz+Wj5km1Sq01l6MglYrbheR7vSpOBX5DHyIw31xEU6fjm/zEPYAS0s09kD5eph6V3zb2EOwV+CRnMgycPWpODX5DfycarxyO5X90Dwf3OLbyv64XWQsZR24+lScmr4C38z2mtmDZnbMzG7o8vzbzOzbZnafmR0xs1L6pU6G6uXQ2ra2rbUtbhcZS1kHrq5Lm5oNA9/MzgFuBq4AdgNXm9nujs2+Acy6+4uAzwDvS7vQ1GX0EXXpVPdFynq1i2Qu68DV8s6p6aeHfxlwzN0fcveTwK3Ale0buPtd7r7aBbgb2JVumSnL8CNq0NcXlXzKOnBrNRovmV477vWSaa3/NIB+Av9C4OG2x8eTtl7eAHy+2xNmVjGzeTObP3HiRP9Vpi3Dj6i1uRqF6bWLlxWmC9TmdPDKmMp4wb3Gi6BywNaOex0wGi8aydtPlH4C37q0dV2Ax8xeB8wC7+/2vLvX3X3W3Wd37tzZf5Vpy/AjarQnor6/TmmmhGGUZkrU99eJ9uRklpGEJ4pofOAayu84J+5hv+McGh+4ZmQz46pHqrR87TctW36S6hEN2m5WP9e0PQ5c1PZ4F/BI50ZmdjlQBV7p7v+XTnlDUix2XxN+RB9Roz2RAl5yo7HQoPLkLbTOexqA5nlPU3nyFlh4+UiOY12HOT399PDvAS4xs4vNbBtwFXCwfQMzezHw18ABd38s/TJTpjXhJQs5/fJQ9UiV1sraU6CtldbIetga90rPhoHv7qeA64DDwAPA7e5+v5ndaGYHks3eD5wHfNrM7jWzgz1+3HjQmvAyalnPZd+CrHvYGvdKTy7XwxfJnRxfWrJ8U5nm8tm1l2ZKLF6/OJIaGgsNqkeqLC0vUZwpUpurBXtadCvr4SvwRUZhairu2Xcyi5cHGWONhQaVQ5U1p3UK0wVNNshIcBdASYOuiSsjlfVc9i3QzLLJEWQPXz0WGbnVc/jt3/8oFDR2JJumHv4mZT3rQAKkiQIyBvqZhz9xsp51IIGKIgW8ZCrIHr7m9YpIiIIMfM3rFZEQBRn4mnUgIiEKcpaOiEheaZaOiIhsSIEvIhIIBb6ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDgi4gEQoEvMiK66I5kLcjlkUVGrfOiO83lJpVDFQCt4SQjox6+yAjoojsyDhT4IiOgi+7IOFDgi4yALroj40CBLzICuuiOjAMFvsgI6KI7Mg50ARQRkRzRBVBERGRDCnwRkUAo8EVEAqHAFxEJhAJfRCQQCnwRkUAo8EVEApHZPHwzOwE0U/hRO4AfpPBzhmWc61Ntgxnn2mC861Ntg2mvreTuOwf5IZkFflrMbH7QLyGMwjjXp9oGM861wXjXp9oGk1ZtOqUjIhIIBb6ISCAmIfDrWRewgXGuT7UNZpxrg/GuT7UNJpXacn8OX0RE+jMJPXwREemDAl9EJBC5CXwz22tmD5rZMTO7ocvzzzCz25Lnv2Zm5RHVdZGZ3WVmD5jZ/Wb2li7bvMrMls3s3uTfO0dRW9v7L5rZQvLeZ12EwGJ/key7+8zs0hHV9dNt++ReM3vKzK7v2GZk+87MPmpmj5nZt9ratpvZF83su8ntc3u89ppkm++a2TUjrO/9Zvad5Pd2h5md3+O16x4DQ6rt3Wb2H22/u309Xrvu3/aQarutra5FM7u3x2uHvd+65sfQjjt3H/t/wDnA94DnA9uAbwK7O7b5HeDDyf2rgNtGVNvzgEuT+88G/q1Lba8CPpfh/lsEdqzz/D7g84ABLwW+ltHv+D+Jv1SSyb4DXgFcCnyrre19wA3J/RuA93Z53XbgoeT2ucn9546ovlcD5yb339utvn6OgSHV9m7gHX383tf92x5GbR3P/ynwzoz2W9f8GNZxl5ce/mXAMXd/yN1PArcCV3ZscyVwS3L/M8CcmdmwC3P3R93968n9/wIeAC4c9vum7ErgEx67GzjfzJ434hrmgO+5exrfvh6Iu38FeKKjuf24ugX49S4v/VXgi+7+hLs/CXwR2DuK+tz9C+5+Knl4N7Ar7fftR499149+/raHVluSEa8FPpXme/ZrnfwYynGXl8C/EHi47fFxzg7VM9skfwDLwAUjqS6RnEZ6MfC1Lk//opl908w+b2YvHGVdgANfMLOjZlbp8nw/+3fYrqL3H12W++7H3f1RiP84gR/rss047D+Aa4k/qXWz0TEwLNclp5s+2uO0RNb77peB77v7d3s8P7L91pEfQznu8hL43XrqnfNJ+9lmaMzsPODvgevd/amOp79OfKri54C/BD47qroSL3f3S4ErgN81s1d0PJ/1vtsGHAA+3eXprPddPzLdfwBmVgVOAY0em2x0DAzDh4CfAn4eeJT41EmnrPfd1azfux/JftsgP3q+rEvbuvsuL4F/HLio7fEu4JFe25jZucAMg33E3DQzmyb+ZTXc/R86n3f3p9z9v5P7dwLTZrZjFLUl7/lIcvsYcAfxx+h2/ezfYboC+Lq7f7/ziaz3HfD91dNbye1jXbbJdP8lg3W/BkSenNzt1McxkDp3/767P+3up4G/6fGeme27JCd+E7it1zaj2G898mMox11eAv8e4BIzuzjpDV4FHOzY5iCwOkr9GuCfeh38aUrOAf4t8IC7/1mPbX5idTzBzC4j3u+PD7u25P2eZWbPXr1PPMj3rY7NDgK/ZbGXAsurHydHpGcvK8t9l2g/rq4B/rHLNoeBV5vZc5PTFq9O2obOzPYCfwgccPdWj236OQaGUVv7ONBv9HjPfv62h+Vy4Dvufrzbk6PYb+vkx3COu2GNPg9hNHsf8Qj294Bq0nYj8YEO8EziUwLHgH8Fnj+iun6J+GPUfcC9yb99wJuBNyfbXAfcTzwD4W7gZSPcb89P3vebSQ2r+669PgNuTvbtAjA7wvoKxAE+09aWyb4j/k/nUWCFuPf0BuJxoCPAd5Pb7cm2s8BH2l57bXLsHQNeP8L6jhGfx1099lZnqv0kcOd6x8AIavtkcjzdRxxgz+usLXl81t/2sGtL2j++epy1bTvq/dYrP4Zy3GlpBRGRQOTllI6IiGyRAl9EJBAKfBGRQCjwRUQCocAXEQmEAl9EJBAKfBGRQPw/JIM72mYnO2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#On compare dans un graphe la différence entre notre prediction \n",
    "plt.scatter(range(20),results,c='r')\n",
    "plt.scatter(range(20),y_test,c='g')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXwV9b3/8dcnJxsBQoAEBBIIS5BFMMEQWVzRFpFWbIsKCogbVkXttdYr1eu13vqrta1VK1Up4FYRxValdWuxti7IkrDvhD1sCRB2yPr9/XEOGGMIAZLMOSfv5+ORR87MmZx5MwnvTL4zZ8acc4iISOiL8DqAiIjUDhW6iEiYUKGLiIQJFbqISJhQoYuIhIlIr1acmJjoUlNTvVq9iEhIysnJ2eWcS6rqOc8KPTU1lezsbK9WLyISksxs04me05CLiEiYUKGLiIQJFbqISJhQoYuIhAkVuohImFChi4iECRW6iEiYCLlCX7PzAL/+aBW67K+IyDeFXKF/vnYXz/97HX9bst3rKCIiQSXkCn3sgFTOTW7GL2Yup/BQsddxRESCRsgVui/CeOJHvdl3pITHP1jpdRwRkaARcoUO0L1NPLdf3Im3c/L4Yu0ur+OIiASFkCx0gLsHpdEpsTE/f2cph4tLvY4jIuK5kC302Cgfv/phL7YUHuZXH6zyOo6IiOdCttABzu/UklsGduS1OZv4z5oCr+OIiHgqpAsd4P7BZ5PWqgkPvL2YfYdLvI4jIuKZkC/02CgfT12bzu6DxTwyc5nXcUREPBPyhQ7QK7kZdw9K471F2/jrgjyv44iIeCIsCh3grks7k9WxBQ+9s4zc/ANexxERqXdhU+iRvgj+MDKDuGgfd72+kCPFZV5HEhGpVzUqdDO7wsxWm1mumT14gmWuNbMVZrbczKbVbsyaaR0fy++vS2dN/gH+V+PpItLAnLTQzcwHTASGAD2AkWbWo9IyacAEYKBzrifwkzrIWiMXdU3irku68FZ2Hn/J0Xi6iDQcNdlDzwJynXPrnXPFwHRgWKVlbgMmOucKAZxz+bUb89T85PI0sjq24OF3l7F82z4vo4iI1JuaFHo7YEuF6bzAvIq6Al3N7Eszm2NmV1T1QmY2zsyyzSy7oKDu3ggU6YvgueszaNYoinGv5rD7YFGdrUtEJFjUpNCtinmV7y4RCaQBlwAjgclmlvCtL3JuknMu0zmXmZSUdKpZT0mrprFMGnMeuw4WccfrCyguLa/T9YmIeK0mhZ4HpFSYTga2VbHMe865EufcBmA1/oL3VO/kBJ4c3pt5G/bw6N+W6y5HIhLWalLo84E0M+toZtHACGBmpWXeBS4FMLNE/EMw62sz6Okalt6OH1/cmWlzNzPps6CIJCJSJyJPtoBzrtTMxgMfAz5gqnNuuZk9BmQ752YGnvuuma0AyoCfOed212XwU/HA4LP9V2X8cBWt42O5OqPyIQARkdBnXg1DZGZmuuzs7HpbX1FpGTdOnUfOpkJevimLgV0S623dIiK1xcxynHOZVT0XNu8UPZmYSB8vjs6kU2ITbn8thxXb9nsdSUSkVjWYQgdo1iiKl2/uS9PYSMa+NI+8wsNeRxIRqTUNqtAB2jRrxCs3Z3G0pIxRk+eSv/+o15FERGpFgyt0gK6tm/LSTX3JP1DEqClzKTxU7HUkEZEz1iALHeC8Di2YPCaTjbsPM2bqPPYf1d2ORCS0NdhCBxjQJZEXR53Hqh37ufml+RwuLvU6kojIaWvQhQ5wabdWPDsigwWbCxk7dT4Hi1TqIhKaGnyhAwzp1YZnR2aQs7mQ0VPmsu+Ihl9EJPSo0AO+17stf7yhD8u27mPU5LnsPawDpSISWlToFQzueRaTRmeyeucBRkyao8vuikhIUaFXcmm3Vky5MZONuw8xYtIc8g/oPHURCQ0q9CpcmJbES2Oz2Lr3CCNenMOOfSp1EQl+KvQT6N+5Ja/enEX+gSKuffErXSZARIKeCr0amakt+POt57P3cDHXvTiHzbtV6iISvFToJ5GeksC02/pxqLiUa1/8ivUFB72OJCJSJRV6DZzTrhlv3NaPkrJyrps0h7U7D3gdSUTkW1ToNdS9TTzTx/UDYMSkOazaoeupi0hwUaGfgrTWTXlzXD+ifBGMnDSHZVv3eR1JROQ4Ffop6pTUhDdv70dcdCTX/2kOi7bs9TqSiAigQj8tHVo2Zvq4fjSLi2L05Lks3FzodSQRERX66UppEceb4/rTvHE0Y6bOY0me9tRFxFsq9DPQNqER0247n/jYKEZPmcfybRpTFxHvqNDPUHLzOKaP60fjaB+jJs/V2S8i4pkaFbqZXWFmq80s18werOL5sWZWYGaLAh+31n7U4JXSIo43xvUjJtLHDX+aq/PURcQTJy10M/MBE4EhQA9gpJn1qGLRN51z6YGPybWcM+h1aNmYabedjy/CGPmnuazTO0pFpJ7VZA89C8h1zq13zhUD04FhdRsrNHVKasK02/oBjpGT5rBp9yGvI4lIA1KTQm8HbKkwnReYV9mPzGyJmb1tZim1ki4EdWnlL/WSsnJGT5lH/n5deldE6kdNCt2qmOcqTf8NSHXO9QZmAa9U+UJm48ws28yyCwoKTi1pCOnauikv3ZTFroNFjJk6j32HdY9SEal7NSn0PKDiHncysK3iAs653c65Y/dr+xNwXlUv5Jyb5JzLdM5lJiUlnU7ekJGeksCk0ZmsLzjELa/M50hxmdeRRCTM1aTQ5wNpZtbRzKKBEcDMiguYWZsKk1cBK2svYui6IC2RZ0aks2BzIXe8nkNJWbnXkUQkjJ200J1zpcB44GP8Rf2Wc265mT1mZlcFFrvHzJab2WLgHmBsXQUONUN6teHxH/Ti36sLuH/GYsrLK49WiYjUjsiaLOSc+wD4oNK8Ryo8ngBMqN1o4WNkVnv2Hi7h1x+tIqFRFI9e1ROzqg5NiIicvhoVupy5H1/cicLDxUz6bD2tm8Vy5yVdvI4kImFGhV5PzIwJQ7qxc/9RnvxoNR1bNmZIrzYn/0IRkRrStVzqkZnx6x/1pk/7BP7rrUW6QqOI1CoVej2LjfIxaUwmiU1iuOWVbLbtPeJ1JBEJEyp0DyQ2iWHq2L4cLS7jlleyOVRU6nUkEQkDKnSPdG3dlOdu6MPqHfu5d/pCynQ6o4icIRW6hy7umsSjV/Vk1sp8fvWB3oslImdGZ7l4bEz/VNYXHGLyFxvolNSE689v73UkEQlRKvQg8PDQ7mzcfYj/eW8Z7VvEcUFaoteRRCQEacglCET6IvjDyAy6JDXhjtdzyM3XzTFE5NSp0INE09gopozNJCYygptfns+eQ8VeRxKREKNCDyLJzeOYNCaTHfuPcvtr2RSV6pK7IlJzKvQg06d9c353zbnM31jIhL8sxTmdzigiNaODokHo++e2ZX3BIX4/aw092sZz64WdvI4kIiFAe+hB6u5BXRjcszW/+nAVs3N3eR1HREKACj1IRUQYv7s2nU6Jjblr2gK27DnsdSQRCXIq9CDWJCaSSWMyKS133P5aju5LKiLVUqEHuY6JjXlmRDord+xnwl+X6CCpiJyQCj0EDOrWmvsu78q7i7bx0pcbvY4jIkFKhR4i7rq0C9/p0Zr/98FKFm4u9DqOiAQhFXqIiIgwfjv8XM5qFsv4aQvZe1jvJBWRb1Khh5BmcVE8d30f8g8c5f4ZGk8XkW9SoYeY9JQEJgzpzqyVO5nyxQav44hIEFGhh6CbBqYyuGdrnvhwFQs0ni4iATUqdDO7wsxWm1mumT1YzXLDzcyZWWbtRZTKzIwnh59Lm4RY7tZ4uogEnLTQzcwHTASGAD2AkWbWo4rlmgL3AHNrO6R8W7NGUUw8Pp6+WOPpIlKjPfQsINc5t945VwxMB4ZVsdz/AU8CR2sxn1Sjd3ICP7+yO7NW5vPnuZu9jiMiHqtJobcDtlSYzgvMO87MMoAU59zfq3shMxtnZtlmll1QUHDKYeXbxg5I5eKuSTz+/grd6UikgatJoVsV847/fW9mEcDvgZ+e7IWcc5Occ5nOucykpKSap5QTMjN+M7w3cdGR/OTNhRSXlnsdSUQ8UpNCzwNSKkwnA9sqTDcFzgH+bWYbgX7ATB0YrT+t4mN54oe9WLZ1P7+ftcbrOCLikZoU+nwgzcw6mlk0MAKYeexJ59w+51yicy7VOZcKzAGucs5l10liqdJ3e57FyKwUXvjPOuas3+11HBHxwEkL3TlXCowHPgZWAm8555ab2WNmdlVdB5Sae3hoDzq0iOO+Nxex70iJ13FEpJ6ZV6e7ZWZmuuxs7cTXtkVb9vKj52cztFcbnh2Z4XUcEallZpbjnKtySFvvFA0z6SkJ3HtZGjMXb+O9RVu9jiMi9UiFHobuvKQz53VozsPvLCOvULeuE2koVOhhKNIXwdPXpeOA+95cTFm53kUq0hCo0MNUSos4HhvWk3kb9zDx01yv44hIPVChh7EfZLRjWHpbnvlkLTmb9ngdR0TqmAo9jJkZv7z6HNomxHLPGzqVUSTcqdDDXNPYKJ4ZkcGO/Ud56J2luiqjSBhToTcAfdo3577vdOXvS7YzIzvP6zgiUkdU6A3Ejy/uTP9OLXlk5jLW7DzgdRwRqQMq9AbCF2E8MyKdJjFR3Pn6Ag4Xl3odSURqmQq9AWkVH8szI9JZV3CQh99dpvF0kTCjQm9gBnZJ5J5Bafx1wVZm5Gg8XSScqNAboHsuS2NA55Y88t4yVu/QeLpIuFChN0C+COPp4+PpORwq0ni6SDhQoTdQrZrG8uyIdNbvOqTxdJEwoUJvwAZ0SeTey9J4Z+FWnZ8uEgZU6A3c3YPSGNilJf/z3jJW7djvdRwROQMq9AbOF2E8fV0G8Y3856cf1Hi6SMhSoQtJTWN4ZkQ6m3Yf5ifTF+n66SIhSoUuAAzonMgj3+vBrJU7efLjVV7HEZHTEOl1AAkeNw5IJTf/IC/+Zz1dkppwTWaK15FE5BRoD12+4ZHv9+CCLon8/J2lzNugm2KIhBIVunxDlC+Cidf3IaV5HLe/ls3m3brJtEioqFGhm9kVZrbazHLN7MEqnv+xmS01s0Vm9oWZ9aj9qFJfmsVFMWVsX8od3PLKfA4c1Z2ORELBSQvdzHzARGAI0AMYWUVhT3PO9XLOpQNPAk/VelKpVx0TG/P8qD5s2HWIu99YqDNfREJATfbQs4Bc59x651wxMB0YVnEB51zFd6Q0BvS/PwwM6JzIL4b15N+rC3j8/ZVexxGRk6jJWS7tgC0VpvOA8ysvZGZ3AfcB0cCgql7IzMYB4wDat29/qlnFAzec34Hc/INM/XIDLZtEc9elXbyOJCInUJM9dKti3rf2wJ1zE51znYH/Bh6u6oWcc5Occ5nOucykpKRTSyqeeXhoD65Ob8tvPl7N5M/Xex1HRE6gJnvoeUDFE5KTgW3VLD8deP5MQklw8UUYv73mXIrLyvnl+yuJjoxgTP9Ur2OJSCU12UOfD6SZWUcziwZGADMrLmBmaRUmhwJray+iBINIXwTPjMjg8u6teeS95Uyft9nrSCJSyUkL3TlXCowHPgZWAm8555ab2WNmdlVgsfFmttzMFuEfR7+xzhKLZ6J8EUy8IYNLzk7iwb8u5YX/rNN11EWCiHn1HzIzM9NlZ2d7sm45M0WlZdw/Ywl/W7yNG/t34JHv98QXUdWhFhGpbWaW45zLrOo5XctFTllMpI9nrkunddMYJn+xgc17DvPMyAziY6O8jibSoOmt/3JaIiKMh7/Xg19efQ6fr93F1c99ycrtukGGiJdU6HJGRvXrwJ9vPZ8DRaVcPfFL3pq/RePqIh5RocsZ69epJR/ccyGZqc154C9LuH/GEg4X685HIvVNhS61IqlpDK/efD73XpbGXxfmMey5L8nNP+B1LJEGRYUutcYXYfzXd7ry6s1Z7DlUzPf/8CUzsjUEI1JfVOhS6y5MS+KDey+kV3Izfvb2Em6YPJd1BQe9jiUS9lToUidax8fyxm39+L+rz2Hp1n0Mefpzfvvxavbr2uoidUaFLnXGF2GM7teBT356MUN6ncVzn+Zy0ZOf8vy/1+mgqUgd0DtFpd4szdvHU/9czaerC0hsEsO4izpyXWZ7msXpDUkiNVXdO0VV6FLvsjfu4al/rmH2ut00ivLxwz7tGDsglbTWTb2OJhL0VOgSlJZv28crszfy7qJtFJeWM7BLS8YO6Migbq10bRiRE1ChS1Dbc6iY6fM389pXm9i+7ygpLRoxpl8qw9Lb0io+1ut4IkFFhS4hobSsnH+s2MnLszcyb8MeADLaJzC451kM7nkWHRMbe5xQxHsqdAk5a3ce4KNlO/h4xQ6WbfVf9Ktr6yYM7nkW3+1xFue0i8dMwzLS8KjQJaTlFR7mnyt28vHyHczbsIdyB63jYxjUrTWXdWtFVqcWunSvNBgqdAkbew4V869V+XyyciefrSngUHEZZtDtrHiyUpvTt2ML+qa2oLXG3iVMqdAlLBWVlpGzqZB5G/Ywf+MeFmzay5GSMgDaJTQivX0Cfdo3p0/7BHq2bUZ0pN5HJ6FPdyySsBQT6WNA50QGdE4EoKSsnBXb9pO9qZAFmwtZuKmQ95dsByA6MoKebePJSGlOevsEMlISSG7eSOPwEla0hy5hbce+oyzc7C/4RVv2snTrPo6WlAOQ2CSa9JQEMto3p0/75mS0TyA2yudxYpHqaQ9dGqyzmsUypFcbhvRqA/j34lfvOMDCLXtZtHkvi7YUMmtlPgAxkRGc16E5/Tu1ZECXlvROTiDKp2EaCR3aQ5cGb9/hErI37WH2ut18tW43KwL3Ro2L9tE3tQUXpiVyabdWdEpsrCEa8ZwOioqcgsJDxczdsJvZ6/wfufn+a7l3aBnHoG6tGNStFVkdWxATqeEZqX8qdJEzkFd4mE9X5fOvVfnMXrebotJyGkf7uKhrEkN7t2FQt1bERWv0UurHGRe6mV0BPAP4gMnOuScqPX8fcCtQChQANzvnNlX3mip0CUVHisuYvW4Xn6zK5x/Ld7LrYBGxUREM6taKq85tx6BurXR6pNSpMyp0M/MBa4DvAHnAfGCkc25FhWUuBeY65w6b2R3AJc6566p7XRW6hLqycsf8jXv4YOl2Pli6g10Hi2jROJqr09sx/LxkerSN9zqihKEzLfT+wKPOucGB6QkAzrlfnWD5DOA559zA6l5XhS7hpLSsnM/X7mJGzhZmrcinuKyc9JQERvfrwNDebXQ6pNSaMz1tsR2wpcJ0HnB+NcvfAnx4giDjgHEA7du3r8GqRUJDpC+CS7u14tJurSg8VMy7i7by2pxN/HTGYn75/gqu69uemwem6nLAUqdqsod+DTDYOXdrYHo0kOWcu7uKZUcB44GLnXNF1b2u9tAl3DnnmL1uN699tYl/rNhBpC+CazOTuf2izqS0iPM6noSoM91DzwNSKkwnA9uqWMnlwEPUoMxFGgIzY2CXRAZ2SWTT7kO88J91vDl/C9PnbeHqjHbceUlnOiU18TqmhJGa7KFH4j8oehmwFf9B0eudc8srLJMBvA1c4ZxbW5MVaw9dGqJte48w6bP1vDFvMyVl5Vyd0Y6ffvds2iU08jqahIjaOG3xSuBp/KctTnXOPW5mjwHZzrmZZjYL6AVsD3zJZufcVdW9pgpdGrKCA0X86fP1vDx7IwA3DUjlzku60CxO13WX6umNRSJBauveI/zuH6t5Z+FW4mOjeOCKsxnZtz0Rukm2nEB1ha53QIh4qF1CI566Np33776Q7m2a8tA7y7j2xa9Yu/OA19EkBKnQRYJAj7bxvHFbP34zvDe5BQe58tnPeeqfaygqLfM6moQQFbpIkDAzrslMYdZ9FzO0Vxue/WQtQ5/9gmVb93kdTUKECl0kyCQ2ieHpERm8cnMWB46W8IM/fskL/1lHWbk3x7skdKjQRYLUxV2T+Ojei7i8e2ue+HAVoybPJX//Ua9jSRBToYsEseaNo/njDX148ke9WbilkCuf/YLZ63Z5HUuClApdJMiZGdf2TeG9uy4gvlEkoybPZeKnuXh1yrEELxW6SIg4+6ymzBx/AUN7t+U3H6/mpzMWU1xa7nUsCSK6zYpICGkSE8mzI9LpktSE389aQ/7+Iv44qg/xsXqHqWgPXSTkmBn3Xp7Gb685lznrd3PtC1+xfd8Rr2NJEFChi4So4ecl89JNfckrPMIPJs5m5fb9XkcSj6nQRULYhWlJzPhxfwBGTJrD4i17PU4kXlKhi4S47m3imfHj/sQ3iuSGyXOZv3GP15HEIyp0kTCQ0iKOt27vT6umMYyZMo/ZuTpXvSFSoYuEiTbNGvHm7f1p3yKOW17JJmdTodeRpJ6p0EXCSFLTGF67NYvW8THc9NI8VmzTgdKGRIUuEmZaNY3lz7eeT+OYSMZMncuGXYe8jiT1RIUuEoaSm8fx2i3nU+5g1OS5bNur89QbAhW6SJjq0qoJr96cxf4jJYyaMpfdB4u8jiR1TIUuEsbOadeMKWP7sm3vEW58aR6Hikq9jiR1SIUuEuayOrbg+RvOY+X2A9zzxkLdKCOMqdBFGoBLu7Xi0at68smqfH75/gqv40gd0dUWRRqI0f06sKHgEFO/3EDHxMaM6Z/qdSSpZTXaQzezK8xstZnlmtmDVTx/kZktMLNSMxte+zFFpDY8NLQ7l3dvxaMzl/Ppqnyv40gtO2mhm5kPmAgMAXoAI82sR6XFNgNjgWm1HVBEao8vwnhmRAbd28RzzxsLWV9w0OtIUotqsoeeBeQ659Y754qB6cCwigs45zY655YAun2KSJBrHBPJi6PPI9Jn3P5ajs58CSM1KfR2wJYK03mBeafMzMaZWbaZZRcUFJzOS4hILUhuHscfRvZhXcFBHvjLEt2fNEzUpNCtinmn9d13zk1yzmU65zKTkpJO5yVEpJZckJbI/YPP5v0l25nyxQav40gtqEmh5wEpFaaTgW11E0dE6tMdF3dmcM/W/OrDVXy1brfXceQM1aTQ5wNpZtbRzKKBEcDMuo0lIvXBzPjtNeeS2jKO8dMW6N6kIe6khe6cKwXGAx8DK4G3nHPLzewxM7sKwMz6mlkecA3wopktr8vQIlJ7msZG8eLo8zhaUsYdf15AUWmZ15HkNJlXB0MyMzNddna2J+sWkW/7YOl27nx9ATcNTOV/v9/T6zhyAmaW45zLrOo5vfVfRAC4slcbxg5I5aUvN/LRsh1ex5HToEIXkeMmXNmN3snNeODtxWzZc9jrOHKKVOgiclxMpI/nRvbBAeOnLaC4VO8VDCUqdBH5hvYt4/jN8N4sztvHEx+u8jqOnAIVuoh8yxXn+MfTp365gY+Xazw9VKjQRaRKE67sRq92zfjZDI2nhwoVuohUKSbSx8Tr++AcjH9jocbTQ4AKXUROqH3LOJ4c3pvFW/by6480nh7sVOgiUq0hvdpwY/8OTPlig85PD3IqdBE5qZ8P7U7v5Gbc/cYCZmRvOfkXiCdU6CJyUjGRPl69OYusji342dtL+MXflnPgaInXsaQSFbqI1EhCXDQv35TFjf078NKXGxnwxL/4n3eX8dmaAh0wDRK6OJeInLKleft48bN1zFq5k6Ml5URGGMnNG9GhZWNSW8aR2CSGRtE+YqJ8NAp8xEZF+D9H+4iN9NEo+uv5sVE+YiIjMKvqfjpSUXUX54qs7zAiEvp6JTfjuev7cLSkjC/W7mLhlkI27j7Mpt2HyNlUyMHTvE9plM+I9kUQFRlBlC+CaF8E0ZER/vmBecfmR/nMPx1ZadoXQWSEERmYFxkRQaTPjj+O8vmfi4zwLx95bJkICyz39eNjX3v8NY5PB14jMM8X4X99r38hqdBF5LTFRvm4vEdrLu/R+hvzS8rKOVJSxtGSMo4Wf/34SOCj6Njj4vLj84tLyykuK6ektJySMv/j4lLnf1xh3rHX3n+0/OuvKSunJLBsSVk5peWO0jJHSXk59TkI4YswfBH+wj/2+dgvj4rT916WxvfPbVvr61ehi0itO7anHB8b5XUUyspdhZIvp6TMUVpe7i/8wPySsvLAcv5lysodJRWWLyv3f43/cfnx5UrL3TdetywwXVb+7eljv2TKyh0JcXWzXVToIhLW/HvNPq9j1Aud5SIiEiZU6CIiYUKFLiISJlToIiJhQoUuIhImVOgiImFChS4iEiZU6CIiYcKzi3OZWQGw6TS/PBHYVYtxakuw5oLgzaZcp0a5Tk045urgnEuq6gnPCv1MmFn2ia425qVgzQXBm025To1ynZqGlktDLiIiYUKFLiISJkK10Cd5HeAEgjUXBG825To1ynVqGlSukBxDFxGRbwvVPXQREalEhS4iEiZCrtDN7AozW21muWb2oMdZNprZUjNbZGbZgXktzOyfZrY28Ll5PeSYamb5Zraswrwqc5jfs4Htt8TM+tRzrkfNbGtgmy0ysysrPDchkGu1mQ2uw1wpZvapma00s+Vmdm9gvqfbrJpcnm4zM4s1s3lmtjiQ6xeB+R3NbG5ge71pZtGB+TGB6dzA86l1kesk2V42sw0Vtll6YH59/vz7zGyhmf09MF3328s5FzIfgA9YB3QCooHFQA8P82wEEivNexJ4MPD4QeDX9ZDjIqAPsOxkOYArgQ8BA/oBc+s516PA/VUs2yPw/YwBOga+z746ytUG6BN43BRYE1i/p9usmlyebrPAv7tJ4HEUMDewHd4CRgTmvwDcEXh8J/BC4PEI4M06/Bk7UbaXgeFVLF+fP//3AdOAvwem63x7hdoeehaQ65xb75wrBqYDwzzOVNkw4JXA41eAq+t6hc65z4A9NcwxDHjV+c0BEsysTT3mOpFhwHTnXJFzbgOQi//7XRe5tjvnFgQeHwBWAu3weJtVk+tE6mWbBf7dBwOTUYEPBwwC3g7Mr7y9jm3Ht4HLzMxqO9dJsp1IvXwvzSwZGApMDkwb9bC9Qq3Q2wFbKkznUf0PfF1zwD/MLMfMxgXmtXbObQf/f1CglUfZTpQjGLbh+MCfu1MrDEl5kivw520G/j27oNlmlXKBx9ssMHywCMgH/on/r4G9zrnSKtZ9PFfg+X1Ay7rIVVU259yxbfZ4YJv93sxiKmerIndtehp4ACgPTLekHpunvJgAAAJuSURBVLZXqBV6Vb+1vDzvcqBzrg8wBLjLzC7yMEtNeb0Nnwc6A+nAduB3gfn1nsvMmgB/AX7inNtf3aJVzKuzbFXk8nybOefKnHPpQDL+vwK6V7Puet1elbOZ2TnABKAb0BdoAfx3fWUzs+8B+c65nIqzq1lvrWUKtULPA1IqTCcD2zzKgnNuW+BzPvAO/h/0ncf+hAt8zvco3olyeLoNnXM7A/8By4E/8fUQQb3mMrMo/KX5unPur4HZnm+zqnIFyzYLZNkL/Bv/+HOCmUVWse7juQLPN6PmQ2+1ke2KwPCVc84VAS9Rv9tsIHCVmW3EPyw8CP8ee51vr1Ar9PlAWuBocTT+AwgzvQhiZo3NrOmxx8B3gWWBPDcGFrsReM+LfNXkmAmMCRzt7wfsOzbMUB8qjVf+AP82O5ZrROCIf0cgDZhXRxkMmAKsdM49VeEpT7fZiXJ5vc3MLMnMEgKPGwGX4x/f/xQYHlis8vY6th2HA/9ygSN+9ZRtVYVfzIZ/rLriNqvT76VzboJzLtk5l4q/o/7lnLuB+thedXF0ty4/8B+lXoN/DO8hD3N0wn+GwWJg+bEs+Me+PgHWBj63qIcsb+D/U7wE/2/7W06UA/+fdxMD228pkFnPuV4LrHdJ4Ae5TYXlHwrkWg0MqcNcF+D/k3YJsCjwcaXX26yaXJ5uM6A3sDCw/mXAIxX+D8zDfzB2BhATmB8bmM4NPN+pDr+XJ8r2r8A2Wwb8ma/PhKm3n//A+i7h67Nc6nx76a3/IiJhItSGXERE5ARU6CIiYUKFLiISJlToIiJhQoUuIhImVOgiImFChS4iEib+P23WDISia1sFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#On affiche l'évolution de la loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
